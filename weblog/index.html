<!DOCTYPE html>
<html>
    <head>
        <title>coderodde - weblog</title>
        <style>
            .MathJax {
                font-size: 13pt;
            }

            h1, h3 {
                text-align: center;
            }
            
            article {
                font-family: "Times New Roman";
                font-size: 13pt;
                text-align: justify;
            }
            
            #main {
                overflow-x: hidden; 
                width: 900px;
                margin: auto;
            }
            
            .lemma_name {
                font-variant: small-caps;
                font-weight: bold;
            }
            
            .exclude_from_lemma_name {
                font-variant: normal;
                font-weight: normal;
            }
            
            .lemma_claim {
                font-weight: bold;
                font-style: italic;
            }
            
            #browser_note {
                width: 350px;
                border: 2px solid black;
                background-color: #ff5555;
                padding: 5px;
                margin: auto;
                font-weight: bold;
                font-size: 10pt;
            }
            
            .sc {
                font-variant: small-caps;
            }
            
            #main {
                overflow-x: scroll;
            }

            .my_italics {
                font-style: italic;
            }

            .figure_style {
                display: block;
                margin-left: auto;
                margin-right: auto;
                padding-top: 40px;
                padding-bottom: 40px;
            }

            #view_count_span {
                font-style: italic;
                font-size: 13pt;
            }

            #counter_paragraph {
                text-align: center;
            }
        </style>
        <link rel="stylesheet" type="text/css" href="algotype_my_config.css">
        <script src="algotype_my.js" type="application/javascript"></script>
        <script>
                Algotype.ALGORITHM_STEP_COMMENT_TAG = "//";
        </script>

    </head>
    <body>
        <div id="main">
            <h1>coderodde's technical weblog</h1>
            <div id="browser_note">For best rendering of formal text, <br/> it is advised to view this page via desktop browsers.</div>
            
            <a href="#mcelp"><h3 id="mcelp">Solving most cost-effective loan problem</h3></a>
            <article>
                <a href="#most-cost-effective-loan-problem.1.introduction"><h4 id="most-cost-effective-loan-problem.1.introduction">1 Introduction</h4></a>
                <p>
                In the most cost-effective loan problem, we are given a directed
                graph of actors where each actor may lend some amount of resources
                it possesses to its child nodes. In case an actor needs more than
                his immediate parents can lend, the parents might need to lend from
                their parents, adjust the interest rate to cover their own expenses,
                and pass the funds to the original lending actor.
                </p>
                
                <p>
                Formally, we are given a directed graph $G = (V, A)$, where $V$
                is the set of actors, and 
                $A \subseteq V^2 \setminus \{ (u, u) \in V^2 \text{ for all } u \in V\}$ is the set of directed
                arcs, excluding self-loops. By $V(G)$ we denote the actor set of $G$, and, likewise, by
                $A(G)$ we denote the arc set of $G$. Given an arc $(u, v) \in A$,
                we call $u$ a <i>parent</i> of $v$, $v$ a <i>child</i> of $u$. 
                Existence of such an arc indicates that $u$ may lend some or all
                of its resources to $v$. Along the graph, we are given a
                <i>potential function</i> $\mathfrak{P} \colon V \to [0, \infty) = \mathbb{R}_{\geq 0}$
                that maps each actor in the graph to the (non-negative) equity that that very
                node has at its disposal. Finally, we are given an <i>interest rate function</i>
                $\mathfrak{I} \colon A \to \mathbb{R}_{\geq 0}$ that maps each arc
                $(u, v) \in A$ to the interest rate the actor $u$ can offer $v$
                when $v$ decides to lend from $u$. From now on, we will call the
                aforementioned amount of resources or equity simply <i>potential</i>.
                </p>
                
                <p>
                Apart from the target data structure, in a problem instance, we
                are given an actor $a \in V$ that applies for a loan, a required
                potential $P \in \mathbb{R}_{> 0}$ and a maximum tolerable 
                interest rate $i \in \mathbb{R}_{\geq 0}$. Our aim, then, is to 
                compute a loan (which may involve more than one lending actor) 
                with minimized interest rates.
                </p>
                
                <a href="#most-cost-effective-loan-problem.2.interest-rate-model"><h4 id="most-cost-effective-loan-problem.2.interest-rate-model">2 Interest rate model</h4></a>
                
                <p>
                Throughout the post, we assume a simple interest rate model. The
                accumulated balance at time $t$ since the time point at which the
                loan was issued, with initial principal $\mathfrak{A}$ and interest
                rate $r$ is given by
                \[
                \mathfrak{A}(1 + r)^t.
                \]
                If we have in the graph, for instance, a directed acyclic path 
                $\langle u, v, z \rangle$ with $r_{u,v}$ being the interest rate
                of $(u, v)$, and $r_{v, z}$ being the interest rate of $(v, z)$,
                the interest rate equation becomes
                \[
                \mathfrak{A}(1 + r_{u,v})^t (1 + r_{v,z})^t = \mathfrak{A}\big[ (1 + r_{u,v})(1 + r_{v,z}) \big]^t = \mathfrak{A}(1 + R)^t.
                \]
                Above, $R$ is the <i>combined</i> interest rate. Dividing both 
                sides by $\mathfrak{A}$ and taking $t$-th root, we obtain
                \begin{aligned}
                    (1 + r_{u,v})(1 + r_{v,z}) &= 1 + R \\
                    R + 1 &= 1 + r_{u,v} + r_{v,z} + r_{u,v}r_{v,z} \\
                    R &= r_{u,v} + r_{v,z} + r_{u,v}r_{v,z}. 
                \end{aligned}
                In general, we write $r_1 + r_2 + r_1 r_2 = \mathfrak{C}(r_1, r_2).$ 
                
                </p>
                
                <p>
                Since we may deal with entire &quot;loan chains,&quot; we need 
                to define the concept of <i>effective interest rate</i>.
                Effective interest rate is given by 
                \[
                I(u, v) =  \min \Bigg(\mathfrak{I}(u, v), \underset{z \in {\rm C {\small hildren}}(G, u)}{\min} \mathfrak{C}(\mathfrak{I}(u, z), I(z, v))\Bigg)    
                \]
                where ${\rm C{\small HILDREN}}(G, u)$ is the set of child nodes
                of $u$, or, formally, $\{ v \colon (u, v) \in A(G) \}.$ 
                Also, for the above formula to be sensible, we need to set $\mathfrak{I}(u, v) = \infty$ for all missing arcs $(u, v) \not\in A(G)$, and $I(u, u) = 0$ for all $u \in V(G)$.
                </p>
                
                <a href="#most-cost-effective-loan-problem.3.problem-statement"><h4 id="most-cost-effective-loan-problem.3.problem-statement">3 Problem statement</h4></a>
                <p>
                Given a problem instance $(G, a, \mathfrak{P}, \mathfrak{I}, P, i)$,
                we wish to compute two additional functions: $\pi$ and $d$.
                $\pi \colon V \to \mathbb{R}_{\geq 0}$ is called a 
                <i>solution potential function</i> and it maps each actor 
                $u$ to potential $\pi(u)$ $u$ can lend, and $d \colon V \to V$
                is called a <i>direction function</i> and it maps each actor
                $u$ to some of its children $d(u)$ to which $\pi(u)$ worth 
                potential is being lent. What comes to constraints, no actor
                $u$ lending some of its potential shall have $I(u, a) > i$,
                since $a$ cannot afford effective interest rates above $i$.
                Also, if it is not possible, due to the first constraint, to
                obtain a loan worth $P$, the loan should be maximized from below
                as close to $P$ as possible.
                </p>
                
                <p>
                In order to implement the first constraint, we need to define the
                set of <i>admissible</i> solution potential functions:
                \[
                \pi_{I, a, i, G} = \{ \pi \colon V(G) \to \mathbb{R}_{\geq 0} \; | \; \pi(u) = 0 \text{ if } I(u, a) > i \}.
                \]
                An admissible solution potential function $\pi$ is said to be <i>valid</i>
                if it also satisfies
                \[
                    \sum_{u \in V} \pi(u) \in [0, P],
                \]
                and we denote that by $\pi \in \mathfrak{V}$.
                </p>
                
                <p>
                Now, we can state the objective formally:
                \[
                \pi = \underset{\pi' \in \mathfrak{V}}{\arg \min}{\Bigg[ P - \sum_{u \in V} \pi'(u) \Bigg]},
                \]
                and
                \[
                d(u) = \underset{z \in {\rm C {\small HILDREN}}(G, u)}{\arg \min} \Bigg[\mathfrak{C}\big(\mathfrak{I}(u, z), I(z, a)\big)\Bigg].
                \]
                </p>
                
                <a href="#most-cost-effective-loan-problem.4.solution-algorithm"><h4 id="most-cost-effective-loan-problem.4.solution-algorithm">4 Solution algorithm</h4></a>
                <p>
                Since the effective interest rate does not decrease with adding
                more directed arcs, we must have that for any actor $a \in V$ the
                most cost-efficient lender is an immediate parent. Whether the second most cost-efficient lender
                is an immediate parent or not depends on effective interest rates.
                Regardless, since we consider effective interest rates, basically we 
                are growing a directed &quot;minimum spanning tree&quot; which we
                extend in a greedy fashion one arc at a time:
                In the very beginning, the tree is trivial and consists only of $a$.
                Then a most cost-effective parent $u_1$ is selected and the arc $(u_1, a)$
                is introduced to the tree. Then $u_2$ is selected. It must not
                belong to $\{a, u_1\}$ while have the lowest possible effective interest rate
                among all nodes in $V \setminus \{ a, u_1 \}$. This procedure continues
                until a desired potential $P$ is collected or until there is no more nodes 
                left with affordable effective interest rates. Below 
                <span style="font-variant: small-caps; font-weight: bolder;">Priority-Queue-Insert</span>$(Q, \langle a, b, c \rangle)$
                stores the triple $\langle a, b, c \rangle$ in the priority queue $Q$ and uses $c$ as a priority key.
                </p>
                <p>
                    <alg-algorithm header="Most-Cost-Effective-Loans$(G, a, \mathfrak{P}, \mathfrak{I}, P, i)$"
                                   algorithm-upper-header-class="upper_header_bar"
                                   algorithm-lower-header-calss="lower_header_bar"
                        algorithm-footer-class="footer_bar">
                        <alg-step>$\text{let } Q \text{ be an empty priority queue}$</alg-step>          
                        <alg-step>$\text{let } \pi \text{ be an empty solution potential function}$</alg-step>          
                        <alg-step>$\text{let } d \text{ be an empty direction function}$</alg-step>          
                        <alg-step>$\text{let } C \leftarrow \{a\}$</alg-step>          
                        <alg-step>$\text{let } P_{\text{collected}} \leftarrow 0 \text{ be the funds currently collected}$</alg-step>
                        <alg-foreach condition="$u \in V(G)$" comment="Initialize the functions">
                            <alg-step>$\pi(u) \leftarrow 0$</alg-step>
                            <alg-step>$d(u) \leftarrow \Nil$</alg-step>
                        </alg-foreach>
                        <alg-foreach condition="$u \in $ Parents$(G, a)$" comment="Initialize the open list">
                            <alg-if condition="$\mathfrak{I}(u, a) \leq i$">
                                <alg-step>Priority-Queue-Insert$(Q, \langle u, a, \mathfrak{I}(u, a) \rangle)$</alg-step>
                            </alg-if>
                        </alg-foreach>
                        <alg-while condition="$|Q| > 0 \; \And \; P_{\text{collected}} < P$">
                            <alg-step>$\langle u, v, i_{\text{current}} \rangle \leftarrow $ Priority-Queue-Extract-Minimum$(Q)$</alg-step>
                            <alg-step>$P_\Delta \leftarrow \min (P - P_{\text{collected}}, \mathfrak{P}(u))$</alg-step>
                            <alg-step>$P_{\text{collected}} \leftarrow P_{\text{collected}} + P_\Delta$</alg-step>
                            <alg-step>$\pi(u) \leftarrow P_\Delta$</alg-step>
                            <alg-step>$d(u) \leftarrow v$</alg-step>
                            <alg-step>$C \leftarrow C \cup \{ u \}$</alg-step>
                            <alg-foreach condition="$z \in$ Parents$(G, u)$">
                                <alg-if condition="$z \not \in C$">
                                    <alg-step>$i_{\text{next}} \leftarrow \mathfrak{C} \big( i_{\text{current}}, \mathfrak{I}(z, u) \big)$</alg-step>
                                    <alg-if condition="$i_{\text{next}} \leq i$">
                                        <alg-step>Priority-Queue-Insert$(Q, \langle z, u, i_{\text{next}}\rangle)$</alg-step>
                                    </alg-if>
                                </alg-if>
                            </alg-foreach>
                        </alg-while>
                        <alg-return>$(\pi, d)$</alg-return>
                    </alg-algorithm>
                </p>
                
                <a href="#most-cost-effective-loan-problem.5.proof-of-correctness"><h4 id="most-cost-effective-loan-problem.5.proof-of-correctness">5 Proof of correctness</h4></a>
                <p>
                <span class="lemma_name">Lemma 1 (Termination)</span>
                <span class="lemma_claim">The algorithm terminates.</span><br/>
                Note that each node removed from the priority queue at line 13 is
                inserted into the closed set $C$ at line 18. Now, the line 23 will not
                reintroduce the same node to $Q$ and so, $Q$ eventually becomes empty (unless
                the algorithm terminates earlier in case the required potential is collected).
                </p>
                <p>
                <span class="lemma_name">Lemma 2 (Optimality)</span>
                <span class="lemma_claim">The algorithm finds most cost-effective loans.</span><br/>
                The effective interest rate function $I$ implicitly defines a transitive closure
                from any actor $u \neq a$ to $a$ assuming the effective interest rate of $u$ is
                within the constraint $I(u, a) \leq i$. That way, $a$ loans from all affordable
                parents (immediate or intermediate) in a greedy fashion: lend as much as possible
                from the most affordable actor, then lend as much as possible from the second most
                affordable actor, and so on until the requested potential is collected or there are
                no more affordable lenders left. It is easy to see that such strategy minimizes
                interest expenses.
                </p>
                <p>
                <span class="lemma_name">Lemma 3 (<span class="exclude_from_lemma_name">$d$</span> is acyclic)</span>
                <span class="lemma_claim">Given a solution direction function $d$, 
                there exist no actor sequence $\langle u_1, u_2, \dots, u_k \rangle$
                such that $d(u_1) = u_2$, $d(u_2) = u_3$, $\dots$, $d(u_{k - 1}) = u_k$ and $d(u_k) = u_1$.</span><br/>
                The only way for such a cycle to emerge is to have $\mathfrak{I}(u_1, u_2) =
                \mathfrak{I}(u_2, u_3) = \dots = \mathfrak{I}(u_{k-1}, u_k) = \mathfrak{I}(u_k, u_1) = 0$, and to pass in $\infty$ as the required potential. Since it is reasonable 
                not to accept infinity for the requested potential, and we have the closed list around in the algorithm, this phenomenon cannot appear.     
                Without loss of generality, suppose the search enters the cycle via $u_1$. When $u_k$ will be
                removed from the priority queue, the arc $(u_k, u_1)$ will be ignored by the line 20 since $u_1$ is in $C$, and
                so, there is no way $d(u_k)$ could be mapped to $u_1$.
                </p>
                <p>
                <span class="lemma_name">Lemma 4</span>
                <span class="lemma_claim">The sum of all solution potentials cannot exceed $P$.</span><br/>
                This is trivially guaranteed by the line 14 and the second test at line 12.
                </p>
                
                <a href="#most-cost-effective-loan-problem.6.running-time-analysis"><h4 id="most-cost-effective-loan-problem.6.running-time-analysis">6 Running time analysis</h4></a>
                <p>
                All the operations except <span class="sc"><b>Priority-Queue-Insert</b></span>
                and <span class="sc"><b>Priority-Queue-Extract-Minimum</b></span> run in $\mathcal{O}(1)$ time.
                In particular, operations on $\pi, d$ and $C$ may be expected to run in $\mathcal{O}(1)$
                on average by resorting to hash-table based maps and sets. With geometric expansion
                scheme <a target="_blank" href="https://coderodde.wordpress.com/2015/08/01/keeping-vectors-efficient/"><b>[1]</b></a>, adding an element to a hash-table based data
                structure runs in <b>amortized</b> $\mathcal{O}(1)$. (If the load factor reaches its
                upper bound, the underlying storage array must be made larger.)
                </p>
                <p>
                What comes to the priority queue $Q$, it clearly stores graph actors without copies
                of a same actor. Now, if we choose a binary heap, both run in $\mathcal{O}(\log V)$ time.
                <span class="sc"><b>Priority-Queue-Insert</b></span> is called no more than $|E|$
                times, and <span class="sc"><b>Priority-Queue-Extract-Minimum</b></span> is called once per
                node, and so we have the running time $\mathcal{O}(E \log V + V \log V) = \mathcal{O}(E \log V)$. By deploying 
                a Fibonacci heap instead, we may reduce this to $\mathcal{O}(E + V \log V)$.
                </p>
                
                <a href="#most-cost-effective-loan-problem.7.future-work"><h4 id="most-cost-effective-loan-problem.7.future-work">7 Future work</h4></a>
                We used a very simple interest rate model in our solution, and
                so it leaves the case where the used interest rate model is more
                realistic. In general, with initial principal $\mathfrak{A}$,
                interest rate $r > 0$, the number of compound periods $n$ per time unit, and time 
                since the moment the loan was issued $t$, the balance grows 
                according to 
                \[
                    \mathfrak{C} = \mathfrak{A}\Bigg( 1 + \frac{r}{n} \Bigg)^{\lfloor nt \rfloor}.
                \]
                Also, as $n \to \infty$, $\mathfrak{C} \to \mathfrak{A}e^{rt}$.
                Combining loans with different parameters in a meaningful way 
                seems to be a non-trivial task but we might address it later.
                
                <a href="#most-cost-effective-loan-problem.8.references"><h4 id="most-cost-effective-loan-problem.8.references">8 References</h4></a>
                <b>[1]</b> <a id="ref1" target="_blank" href="https://coderodde.wordpress.com/2015/08/01/keeping-vectors-efficient/">Keeping vectors efficient</a> (Retrieved 2018-03-09.)
            </article>
            <!--
            <a href="#inclusion-exclusion-principle"><h3 id="inclusion-exclusion-principle">Proving inclusion-exclusion principle</h3></a>
            
            <article>
                <p>It is easy to check pictorially using a Venn diagram that given two sets, $A_1$ and $A_2$, $|A_1 \cup A_2| = |A_1| + |A_2| - |A_1 \cap A_2|$. 
                   The <b>inclusion-exclusion principle</b> generalizes the previous identity to a collection of sets $A_1, A_2, \dots, A_n$, and is given by</p>
                \begin{aligned}
                    \Bigg\vert \bigcup_{i = 1}^n A_i \Bigg\vert = \sum_{i = 1}^n (-1)^{i + 1} \Bigg(\sum_{1 \leq k_1 < \dots < k_i \leq n}\Bigg\vert  \bigcap_{j = 1}^i A_{k_j}  \Bigg\vert\Bigg).
                \end{aligned}
                <p>We will use induction to prove also any case $n > 2$. Let $B = \bigcup_{i = 1}^n A_i$, and $A_{n + 1}$ given. Using the same principle for the case of only two sets, we must have
                \[
                    |B \cup A_{n + 1}| = |B| + |A_{n + 1}| - |B \cap A_{n + 1}|.
                \]
                Next, we need a simple lemma for extending distributive law to multiple sets:
                </p> 
                <p>
                    <span class="lemma_name">Lemma 1 (Distributive law for multiple sets)</span>
                    <span class="lemma_claim">For any sets $A_1, \dots, A_n, B$, we must have
                    $$
                    \Bigg( \bigcup_{i = 1}^n A_i \Bigg) \cap B = \bigcup_{i = 1}^n (A_i \cap B).
                    $$
                    </span><br/>
                    First, let us verify the base case $n = 2$:
                    \begin{aligned}
                    \Bigg( \bigcup_{i = 1}^2 A_i \Bigg) \cap B &= (A_1 \cup A_2) \cap B \\
                                                               &= (A_1 \cap B) \cup (A_2 \cap B) && \text{by distributive law}\\
                                                               &= \bigcup_{i = 1}^2 (A_i \cap B).
                    \end{aligned}
                    
                    Suppose the identity holds for $A_1, \dots, A_n$. Now, 
                    \begin{aligned}
                    \Bigg( \bigcup_{i = 1}^{n + 1} A_i \Bigg) \cap B &= \Bigg[ \Bigg( \bigcup_{i = 1}^n A_i \Bigg) \cup A_{n + 1} \Bigg] \cap B \\
                                                                     &= \Bigg[ \Bigg( \bigcup_{i = 1}^n A_i \Bigg) \cap B \Bigg] \cup \Bigg[ A_{n + 1} \cap B \Bigg] && \text{by distributive law}\\
                                                                     &= \Bigg[ \bigcup_{i = 1}^n (A_i \cap B) \Bigg] \cup \Bigg[ A_{n + 1} \cap B \Bigg] && \text{by induction hypothesis} \\
                                                                     &= \bigcup_{i = 1}^{n + 1} (A_i \cap B)
                    \end{aligned}
                    as desired. Now
                    \begin{aligned}
                        \Bigg\lvert \bigcup_{i = 1}^{n + 1} A_i \Bigg\rvert &= \Bigg\lvert \Bigg( \bigcup_{i = 1}^n A_i \Bigg) \cup A_{n + 1} \Bigg\rvert \\
                                                                            &= \Bigg\lvert \bigcup_{i = 1}^n A_i \Bigg\rvert + \Bigg\lvert A_{n + 1} \Bigg\rvert - \Bigg\lvert \Bigg( \bigcup_{i = 1}^n A_i \Bigg) \cap A_{n + 1}\Bigg\rvert\\
                                                                            &= \Bigg\lvert \bigcup_{i = 1}^n A_i \Bigg\rvert + \Bigg\lvert A_{n + 1} \Bigg\rvert - \Bigg\lvert \bigcup_{i = 1}^n (A_i \cap A_{n + 1}) \Bigg\rvert \quad \text{by distributive law} \\
                         &= \sum_{i = 1}^n (-1)^{i + 1} \Bigg(\sum_{1 \leq k_1 < \dots < k_i \leq n}\Bigg\vert  \bigcap_{j = 1}^i A_{k_j}  \Bigg\vert\Bigg) \quad \text{by induction hypothesis} \\
                         &+ \vert A_{n + 1} \vert - \sum_{i = 1}^n (-1)^{i + 1} \Bigg( \sum_{1 \leq k_1 < \dots k_i\leq n} \Bigg\vert \bigcap_{j = 1}^i (A_{k_j} \cap A_{n+1})\Bigg\vert \Bigg) \\
                         
                         &= \vert A_{n + 1} \vert - \sum_{i = 1}^n (-1)^{i + 1} \Bigg( \sum_{1 \leq k_1 < \dots k_i\leq n} \Bigg\vert \bigcap_{j = 1}^i (A_{k_j} \cap A_{n+1})\Bigg\vert \Bigg) \\
                         
                         &+ \lvert A_{n + 1} \rvert - \Bigg[ \sum_{i = 1}^n | A_i \cap A_{n + 1} | - \sum_{1 \leq i < j \leq n} \lvert (A_i \cap A_{n + 1}) \cap (A_j \cap A_{n + 1}) \rvert + \dots + (-1)^n \sum_{1 \leq x_1 < x_2 < \dots x_{n - 1} \leq n} \lvert (A_{x_1} \cap A_{n + 1}) \cap \dots \cap (A_{x_{n - 1}} \cap A_{n + 1}) \rvert + (-1)^{n + 1} \Bigg\lvert \bigcap_{i = 1}^n (A_i \cap A_{n + 1}) \Bigg\rvert\Bigg] \\
                         &= \sum_{i = 1}^n \lvert A_i \rvert - \sum_{1 \leq i < j \leq n} \lvert A_i \cap A_j \rvert + \sum_{1 \leq i < j < k \leq n} \lvert A_i \cap A_j \cap A_k \rvert + \dots + (-1)^{n + 1} \lvert A_1 \cap \dots \cap A_n\rvert \\
                         &+ \lvert A_{n + 1} \rvert - \Bigg[ \sum_{i = 1}^n \lvert A_i \cap A_{n + 1} \rvert - \sum_{1 \leq i < j \leq n} \lvert A_i \cap A_j \cap A_{n + 1} \rvert + \dots + (-1)^n \sum_{1 \leq x_1 < x_2 < \dots < x_{n - 1} \leq n} \lvert A_{x_1} \cap A_{x_2} \dots A_{x_{n - 1}} \cap A_{n + 1} \rvert + (-1)^{n + 1} \Bigg\lvert \bigcap_{i = 1}^{n + 1} A_i \Bigg\rvert \Bigg] \\
                         &= \sum_{i = 1}^{n + 1} \lvert A_i \rvert - \sum_{1 \leq i < j \leq n + 1} \lvert A_i \cap A_j \rvert + \sum_{1 \leq i < j < k \leq n + 1} \lvert A_i \cap A_j \cap A_k \rvert + \dots + (-1)^{n + 2} \Bigg\lvert \bigcap_{i = 1}^{n + 1} A_i \Bigg\rvert.
                    \end{aligned}
                </p>
            </article>
            -->
            <a href="#biddfs"><h3 id="biddfs">Richard E. Korf's bidirectional depth-first iterative-deepening pathfinding algorithm</h3></a>
            <article>
                <p>
                    In this post, I will briefly discuss a rather simple graph search technique <b>[1]</b> that turned out to be rather efficient on sparse, directed, unweighted graphs. 
                Before that, I will review some terminology. 
                A directed, unweighted graph $G$ is an ordered pair $(V, A)$, where $V$ is the set of <i>nodes</i>, and $A \subseteq V \times V$ is the set of directed <i>arcs</i>.
                Given two terminal nodes $s, t \in V$, we wish to find a <i>shortest</i> $s,t$-path, or, in other words, 
                    a path that connects the node $s$ to the node $t$ using minimum number of arcs.
                According to common jargon, $s$ is called a source node, and $t$ is called a target node.
                    Also, by $A(G)$ we will denote the arc set of $G$.
                Also, if we are given an arc $a = (u, v)$, we call $u$ a <i>parent</i> of $v$, $v$ a <i>child</i> of $u$. 
                Finally, we reserve the term &quot; search frontier&quot; to depict the set of nodes no further from the main node than 
                    $\Delta \in \mathbb{N} \cup \{ 0 \}$ steps.
                </p>
                
                <p>
                What comes to the actual algorithm in question, it utilizes iterative deepening in order to reduce memory consumption. 
                It first checks that the invocation is trivial (the source node is the target node), 
                    and if so, returns $\langle s \rangle = \langle t \rangle$. 
                Now, let $F_f^k$ be the set of nodes in $G$ that are reachable from $s$ in $k$ hops following the directions of the arcs.
                Let also $F_b^k$ be the set of nodes in $G$ that are reachable from $t$ in $k$ hops following the opposite directions of the arcs.
                Formally, the algorithm computes $F_f^k$ and $F_b^k$ for $k = 0, 1, \dots$ until $F_f^k$ intersects $F_b^k$ for some $k$ and returns a &quot;meeting node&quot; $\mu$ for which $\mu \in F_f^k \cap F_b^k$.
                After finding such a meeting node, the shortest path is reconstructed by recursively finding the shortest $s, 
                    \mu$-path and appending the node stack of the backward search process. 
                    Otherwise, if the meeting node is not found, $k$ is incremented, and the search repeats once again. 
                There is, however, a catch. Suppose a simple graph $V = \{s, u_1, u_2, t\}, A = \{ (s, u_1), (u_1, u_2), (u_2, t) \}$ is searched for a shortest $s,t$-path.
                Now, the search procedure currently under discussion will return with no path, 
                    and that happens because the forward and backward search frontiers, F_f^k and F_b^k, respectively, 
                    go &quot;through&quot; each other:
                For $k = 1$, $F_f^k = \{ u_1 \}$ and $F_b^k = \{ u_2 \}$, and if $k = 2$, $F_f^k = \{ u_2 \}$ and $F_b^k = \{ u_1 \}$,
                    and so, the search frontiers are not able to 
                agree on a meeting node. In order to remedy this, for each turn of the backward search, 
                it is run twice:
                    once for detecting shortest paths with the even number of arcs, and once for detecting shortest paths with the odd number of arcs. 
                    Or, in another words, for each $k$ in forward direction, two backward searches are conducted: $F_b^k$ and $F_b^{k + 1}$.
                Last but not least, if there is no $s,t$-path, the algorith will stuck.
                </p>
                
                <p>
                As it became evident, BIDDFS is also bidirectional, so we need to to discuss shortly the benefits of such an arrangement. 
                Suppose that the average out-degree is $d$ and the shortest path consists of $N$ arcs. Now the total work done by unidirectional breadth-first search
                is roughly
                \[
                W_1 = \sum_{i=0}^N d_i = \Theta(d^N),
                \]
                </p>
                <p>where $N$ is the number of arcs on the shortest path, and $d$ is the average out-degree. Of course, 
                the above expression requires little variance in nodes' out-degrees. 
                    If, however, we denote the average out-degree by $d_o$ and average in-degree by $d_i$,
                the work done by bidirectional breadth-first search is
                \[
                W_2 = \sum_{j=0}^{N/2} d_i^j + \sum_{j=0}^{N/2} d_o^j.
                \]
                Now, if we set $d_i = d_o = d$, the speedup is roughly
                \begin{aligned}
                \frac{W_1}{W_2} = \frac{\sum_{j = 0}^N d^j}{2 \sum_{j = 0}^{N / 2} d^j}
                                = \frac{\frac{1 - d^{N + 1}}{1 - d}}{2 \frac{1 - d^{N / 2 + 1}}{1 - d}}
                                = \frac{1 - d^{N + 1}}{2 (1 - d^{N / 2 + 1})}
                                =\frac{d^{N + 1} - 1}{2(d^{N / 2 + 1} - 1)}
                                \approx \frac{d^{N + 1}}{2d^{N / 2 + 1}}
                                = \frac{d^{N / 2}}{2}
                                = \Theta(d^{N/2}),
                \end{aligned}
                </p>
                which implies exponential speedup in shortest path length.
                
                <p align="center">
                    <img src="BDFID.png" width="400px"/>
                </p>
                
                <p>
                    The figures <b>1 (A)</b> and <b>1 (B)</b> demonstrate how the two search spaces go "through" each other, and the figure <b>1 (C)</b> shows how to address that issue.
                </p>
                
                <p>
                    Before we proceed to pseudocode, we have to review some notational conventions.
                    Given a graph $G$, the set of all children of a node $u \in V(G)$ is written as 
                    ${\rm C{\small HILDREN}}(G, u)$. Also, the set of all parents of a node 
                    $u$ is written as ${\rm P{\small ARENTS}}(G, u)$. The algorithm 1 reconstructs the 
                    shortest path by recursively searching the shortest $s,\mu$-path from the source node
                    and to the meeting node $\mu$, appends the $B$-path to the resulting path and returning the
                    concatenation. The algorithm 2 is the forward search routine that colors all the nodes
                    exactly $\Delta$ hops away from the source. Note that it may color the nodes 
                    less than $\Delta$ hops away, since it may &quot;make a turn&quot; and proceed towards
                    closer nodes. It is, however, sufficient for us that the routine does not reach the nodes
                    farther than $\Delta$ steps away. The algorithm 3, like the algorithm 2, makes a 
                    depth-first search backwards, but along opposite direction (from child to parent). When
                    the node $\mu$ for which $\mu \in F_b^k$, the search is over and the shortest path
                    is reconstructed via algorithm 1. Finally, the algorithm 4 performs the actual search
                    by increasingly going deeper in the graph until the two search frontiers $F_f^k, F_b^k$ (or $F_f^k, F_b^{k+1}$) intersect.
                </p>
                
                <a href="#biddfs_pseudocode"><h3 id="biddfs_pseudocode">Pseudocode</h3></a>
                <p>
                    <alg-algorithm header="Algorithm 1 Build-Path($s, \mu, B, G$)"
                                   algorithm-upper-header-class="upper_header_bar"
                                   algorithm-lower-header-class="lower_header_bar"
                                   algorithm-footer-class="footer_bar">
                        <alg-step>$\pi \leftarrow$ Find-Shortest-Path$(G, s, \mu)$</alg-step>
                        <alg-step>$\text{remove the last node from } \pi$</alg-step>
                        <alg-return>$\pi \circ B$</alg-return>
                    </alg-algorithm>
                </p>
                
                <p>
                    <alg-algorithm header="Algorithm 2 Depth-Limited-Search-Forward$(G, u, \Delta, F)$"
                                   algorithm-upper-header-class="upper_header_bar"
                                   algorithm-lower-header-class="lower_header_bar"
                                   algorithm-footer-class="footer_bar">
                        <alg-if condition="$\Delta = 0$">
                            <alg-step>$F \leftarrow F \cup \{ u \}$</alg-step>
                            <alg-return></alg-return>
                        </alg-if>
                        <alg-foreach condition="$v \in $ Children$(G, u)$">
                            <alg-step>Depth-Limited-Search-Forward$(G, v, \Delta - 1, F)$</alg-step>
                        </alg-foreach>
                    </alg-algorithm>
                </p>
                
                <p>
                    <alg-algorithm header="Algorithm 3 Depth-Limited-Search-Backward$(G, u, \Delta, B, F)$"
                                   algorithm-upper-header-class="upper_header_bar"
                                   algorithm-lower-header-class="lower_header_bar"
                                   algorithm-footer-class="footer_bar">
                        <alg-step>$\text{prepend } u \text{ to } B$</alg-step>
                        <alg-if condition="$\Delta = 0$">
                            <alg-if condition="$u \in F$">
                                <alg-return>$u$</alg-return>
                            </alg-if>
                            <alg-step>$\text{remove the head node in }B$</alg-step>
                            <alg-return>$\Nil$</alg-return>
                        </alg-if>
                        <alg-foreach condition="$v \in $Parents$(G, u)$">
                            <alg-step>$\mu \leftarrow $Depth-Limited-Search-Backward$(G, v, \Delta - 1, B, F)$</alg-step>
                            <alg-if condition="$\mu \neq \Nil$">
                                <alg-return>$\mu$</alg-return>
                            </alg-if>
                        </alg-foreach>
                        <alg-step>$\text{remove the head node in } B$</alg-step>
                        <alg-return>$\Nil$</alg-return>
                    </alg-algorithm>
                </p>
               
                
                <p>
                    <alg-algorithm header="Algorithm 4 Find-Shortesst-Path($G, s, t$)"
                                   comment="The main search routine"
                                   algorithm-upper-header-class="upper_header_bar"
                                   algorithm-lower-header-class="lower_header_bar"
                                   algorithm-footer-class="footer_bar">
                        <alg-if condition="$s = t$">
                            <alg-return>$\langle s \rangle$</alg-return>
                        </alg-if>
                        <alg-step>$\langle F, B, \Delta \rangle \leftarrow \langle \emptyset, \emptyset, 0 \rangle$</alg-step>
                        <alg-forever>
                            <alg-step>Depth-Limited-Search-Forward$(G, s, \Delta, F)$</alg-step>
                            <alg-foreach condition="$d = \Delta, \Delta + 1$">
                                <alg-step>$\mu \leftarrow $ Depth-Limited-Search-Backward$(G, t, d, B, F)$</alg-step>

                                <alg-if condition="$\mu \neq \Nil$">
                                    <alg-return>Build-Path$(s, \mu, B, G)$</alg-return>
                                </alg-if>
                            </alg-foreach>
                            <alg-step>$F \leftarrow \emptyset$</alg-step>
                            <alg-step>$\Delta \leftarrow \Delta + 1$</alg-step>
                        </alg-forever>
                    </alg-algorithm>
                </p>
                
                <p>
                    The results are rather impressive. What comes to solving 15-puzzles, while iterative deepening A* dominates BID by a factor of three or so, on general graphs, BID 
                    is faster than iterative deepening depth-first search by an order of magnitude, and BID outperforms unidirectional breadth-first search by three orders
                    of magnitude. The following listing is a typical output of the benchmarking program:
                </p>
                
                <pre>
                    <code>
*** 15-puzzle graph benchmark ***
Seed = 1544375493597
BreadthFirstSearch in 1050 milliseconds. Path length: 18
IterativeDeepeningDepthFirstSearch in 36302 milliseconds. Path length: 18
BidirectionalIterativeDeepeningDepthFirstSearch in 20 milliseconds. Path length: 18
IterativeDeepeningAStar in 116 milliseconds. Path length: 18
Algorithms agree: true

*** General graph benchmark ***
Seed = 1544375531134
BidirectionalIterativeDeepeningDepthFirstSearch in 0 milliseconds. Path length: 5
IterativeDeepeningDepthFirstSearch in 10 milliseconds. Path length: 5
BreadthFirstSearch in 472 milliseconds. Path length: 5
                    </code>
                </pre>
                
                <a href="#bdfid.references"><h4 id="bdfid.references">8 References</h4></a>
                <b>[1]</b> <a id="ref1" target="_blank" href="https://academiccommons.columbia.edu/doi/10.7916/D8BK1M9V/download">Korf, R. E., & Columbia University. (1985). Depth-first iterative-deepening: An optimal admissible tree search. New York: Department of Computer Science, Columbia University.</a> (Retrieved 2019-06-05.)
            
            </article>
            
            <a href="#on_radial_area"><h3 id="on_radial_area">Computing radial sets with overlapping areas</h3></a>
            <article>
                <p align="center">May 20, 2019</p>
                
                <p  >
                    In this post, we shall compute the radial sets without overlapping areas in polar coordinates.
                    A function $r = f(\theta)$ is said to be <i>monotonically reducing</i> on the interval $I = [a, b]$, if
                    we have $f(\theta) \geq f(\theta + 2\pi)$ for any $\theta \in [a, b - 2\pi]$. Now, the radial set $A_f(a, b) = \{ (r \cos \theta, r \sin \theta) \colon r \in [0, f(\theta)], \theta \in [a, b] \}$ is calculated as
                    \[
                        A = \frac{1}{2} \int_a^b f^2(\theta) \, d\theta,
                    \]
                    if $b \leq a + 2\pi$. In case $b > a + 2\pi$, some of the area will overlap. We can, however, deal with that issue:
                    \begin{equation}
                    |A_f(a,b)| = \frac{1}{2} \Bigg[ \int_a^b f^2(\theta)\,d\theta - \int_{a + 2\pi}^b f^2(\theta)\, d\theta \Bigg].
                    \end{equation}
                </p>
                <p>Now, suppose $f(\theta) \leq f(\theta + 2\pi)$. We must have
                \[
                |A_f(a, b)| = \frac{1}{2} \Bigg[ \int_a^b f^2(\theta) \,d\theta - \int_a^{b - 2\pi} f^2(\theta) \, d\theta \Bigg].
                \]
                </p>
            </article>
            <h3>Rotating a parabola</h3>
            <article>
                <p>
                In this post, we will investigate how to rotate a parabola $P$ in a plane. 
                Let $V = (x_V, y_V)$ be the vertex of $P$ and $\alpha$ be the angle in radians between axis of symmetry 
                and the axis parallel to the $x$-axis $(y = y_V)$, call it $\ell$. As the value of $\alpha$ grows, $P$ rotates counter-clockwise direction.
                Finally, we are given a parameter $\beta$, which defines geometry of $P$, $\beta t^2$. When 
                $\alpha = 0$, $P$ opens upwards. When $\alpha = \pi / 2$, $P$ opens to the left.
                What we wish to accomplish is to find out how to rotate the parabola around their vertices.
                </p>
                
                <p>
                Next, we need a way to calculate the position and slope of a tangent line (call it $T$) visiting $V$ such that it makes an angle of $\alpha$ radians with $\ell$.
                </p>
                
                <p>
                    \begin{align}
                    \frac{y - y_V}{x - x_V} &= \tan \alpha \\
                    y &= (\tan \alpha) (x - x_V) + y_V \\
                      &= (\tan \alpha) x - (\tan \alpha) x_V + y_V \\
                      &= \ell(x).
                    \end{align}
                </p>
                
                <p>
                    Now, given an $x \in \mathbb{R}$, 
                    \begin{aligned} 
                    t &= d((x, \ell(x)), (x_V, y_V)) \\
                      &= \sqrt{(x - x_V)^2 + (\ell(x) - y_V)^2},
                    \end{aligned}
                </p>
                
                <p>
                    which implies 
                    \[
                        \beta t^2 = \beta \big[ (x - x_V)^2 + (\ell(x) - y_V)^2 \big].
                    \]
                    Given $t \in \mathbb{R}$, we move from $V$ $t$ units towards positive part of 
                    $T$ and then $\beta t^2$ upwards. Note that, for example, if $\alpha \in (\pi / 2, 3\pi / 2)$,
                    "positive'' becomes "negative" and "upwards" becomes "downwards".  
                </p>
                
                <p>
                    Let $V_t$ be the point on a parabola with vertex $V$, vertex tangent angle $\alpha$ and the distance from $V$ $t$, the corresponding point $V_t$ is specified by 
                    \begin{aligned}
                        V_t &= V + (t\cos \alpha, t\sin \alpha) + (\beta t^2 \sin \alpha, \beta t^2 \cos \alpha) \\
                            &= (x_V + t\cos \alpha + \beta t^2 \sin \alpha, \; y_V + t \sin \alpha + \beta t^2 \cos \alpha)
                    \end{aligned}
                </p>    
                
                <p>
                The tangent line is obviously defined by $y = $
                In particular,
                Assuming the angle $\alpha$, its equation is</p>

                <p>
                \begin{align}
                    \frac{y - y_V}{x - x_V} &= \tan \alpha \\
                    y - y_V &= (\tan \alpha)(x - x_V) \\
                    y &= (\tan \alpha)(x - x_V) + y_V \\
                    y &= (\tan \alpha)x + y_V - (\tan \alpha) x_V.
                \end{align}
                </p>
            </article>
        
        <h3>Deriving the polynomial derivatives</h3>
        <article>
            <p>Let $f(x) = x^n$, where $n$ is a non-negative integer Now we have.</p>
            <p>
\begin{aligned}
\frac{\mathrm{d}}{\mathrm{d}x}f(x)
    &= \lim_{h \to 0} \frac{f(x + h) - f(x)}{h} \\
    &= \lim_{h \to 0} \frac{(x + h)^n - x^n}{h}\\
    &= \lim_{h \to 0} \frac{\sum_{k = 0}^n \binom{n}{k} x^{n - k}h^k - x^n}{h} \\
    &= \lim_{h \to 0} \frac{x^n + nx^{n - 1}h + \sum_{k = 2}^n \binom{n}{k} x^{n - k}h^k - x^n}{h} \\
    &= \lim_{h \to 0} \big[ nx^{n - 1} \big] + \lim_{h \to 0}\Bigg[ \frac{h^2 \sum_{k=2}^n \binom{n}{k} x^{n - k}h^{k - 2} }{h} \Bigg] \\
    &= nx^{n - 1} + \lim_{h \to 0} \Bigg[ h \sum_{k = 2}^n \binom{n}{k}x^{n - k}h^{k - 2} \Bigg] \\
    &= nx^{n - 1}
    \end{aligned}
            </p>
<p>Next, keeping $n$ in the set of positive integers, suppose $f(x) = x^{-n}$. Now we have</p>
<p>
\begin{aligned}
\frac{\mathrm{d}}{\mathrm{d}x}f(x) &= \lim_{h \to 0} \frac{\frac{1}{(x + h)^n} - \frac{1}{x^n}} 
{h} \\
    &= \lim_{h \to 0} \frac{1}{h} \frac{x^n - (x + h)^n}{x^n (x + h)^n } \\
    &= \lim_{h \to 0} \frac{1}{h} \frac{x^n - \sum_{k = 0}^n \binom{n}{k} x^{n - k}h^k}{x^n (x + h)^n} \\
    &= \lim_{h \to 0} \frac{x^n - x^n - nx^{n - 1}h - \sum_{k = 2}^n \binom{n}{k} x^{n - k}h^k}{hx^n(x + h)^n} \\
    &= \lim_{h \to 0} \Bigg[ \frac{-nx^{n - 1}h}{hx^n (x + h)^n} - \frac{h^2\sum_{k = 2}^n \binom{n}{k} x^{n - k}h^{k - 2}}{hx^n (x + h)^n} \Bigg] \\
    &= \lim_{h \to 0} \frac{-nx^{n - 1}}{x^n (x + h)^n} - \lim_{h \to 0} h \frac{\sum_{k = 2}^n \binom{n}{k} x^{n - k}h^{k - 2}}{x^n(x + h)^n} \\
    &= \frac{\lim_{h \to 0} -nx^{n - 1}}{\lim_{h \to 0} x^n (x + h)^n} \\
    &= \frac{-nx^{n - 1}}{ x^{2n} } \\
    &= -nx^{-n - 1}.
\end{aligned}</p>
        </article>

        <a href="#gtif"><h3>Generating trigonometric identities from $f_q(x) = \sin^qx$</h3></a>
        <article>   
	<p>
	In this post, we will take a look, what identities may be generated from a simple equation $f_q(x) = \sin^q x$, where $q \in \mathbb{R} \setminus
    \{ 0 \}$. The idea is to, first, define the inverse function $f_q^{-1}$ and derivate it via direct derivation and via using the known identity
$$
    \frac{d}{dx} f_q^{-1}(x) \overset{(1)}{=} \frac{1}{f'_q(f_q^{-1}(x))},
$$
after which we compare the two results and cancel the common factors, possibly, leaving us with something of interest.

        <p>
        Let us begin with defining the inverse function of $f_q(x)$:
        \[
            \begin{aligned}
                 y &= \sin^q x          \\
            \sin x &= y^{1/q}           \\ 
                 x &= \arcsin (y^{1/q}) \\
            \end{aligned}
        \]
	Next, for convenience, we exchange the variables in the most recent identity:
        \[
            f_q^{-1}(x) = \arcsin (x^{1/q}).
        \]
        Derivating $f_q^{-1}(x)$ directly gives us:
        \[
            \begin{aligned}
                \frac{d}{dx} f_q^{-1}(x) &= \frac{1}{\sqrt{1 - x^{2/q}}} \frac{d}{dx}(x^{1/q}) \\
                                         &= \frac{1}{\sqrt{1 - x^{2/q}}} \frac{x^{1/q}}{qx}    \\
                                         &= \frac{1}{qx^{1 - 1/q}\sqrt{1 - x^{2/q}}}.          \\
            \end{aligned}
        \]
        Now, we need the derivative of $f_q(x)$:
        $$
            f'_q(x) = q \sin^{q - 1} x \cos x. 
        $$
        What comes to the identity (1), it yields
        \[
            \begin{aligned}
                \frac{d}{dx} f_q^{-1}(x) &= \frac{1}{f'_q(\arcsin(x^{1/q}))} \\
                                         &= \frac{1}{q \sin^{q - 1} (\arcsin(x^{1/q})) \cos (\arcsin(x^{1/q}))} \\
                                         &= \frac{1}{q x^{1 - 1/q} \cos (\arcsin(x^{1/q}))}.
            \end{aligned}
        \]
        Since 
        $$
            \frac{d}{dx} f_q^{-1}(x) = \frac{1}{f'_q(f_q^{-1}(x))},
        $$
        we must have
        $$
            \frac{1}{\underbrace{qx^{1 - 1/q}}_{\alpha}\sqrt{1 - x^{2/q}}} = \frac{1}{\underbrace{q x^{1 - 1/q}}_{\alpha} \cos (\arcsin(x^{1/q}))},
        $$
        which leads to the desired equation:
        $$
        I_q(x) = \cos(\arcsin(x^{1/q})) = \sqrt{1 - x^{2/q}}.
        $$
        Exchanging $1/q$ with $q$ in $I_q(x)$, we obtain
        $$
        \cos(\arcsin(x^{q})) = \sqrt{1 - x^{2q}}.
        $$
        Finally, since the domain of $\arcsin$ is $[-1, 1]$, it is safe to assume, that the domain of $I_q$ is $[-1, 1]$. Also, note that we disallowed the case $q = 0$, since it would yield a division by zero in the calculation, and the function $f_0(x) = \sin^0 x = 1$ does not have an inverse.

    </article> 

        <a href="#calc-force"><h3>Calculating the force between a charged particle and a charged line with infitesimal density</h3></a>
        <article>
            <p>
            In this post, we are given a particle with electric charge $Q_1$, and an (infinite) line with finite charge $Q_2$ with infinitesimal charge density. The shortest distance to the line is $d$. We wish to compute the magnetic pull between the line and the particle. Suppose we bisect the line into $n \in \mathbb{N}$ equidistant parts. Now, the charge density of the line is given by
            $$
            \frac{Q_2}{n}.
            $$
            If we fix $x \in \mathbb{R},$ the electromagnetic pull between the particle and the line is given by
            $$
            \frac{kQ_1Q_2\Delta x}{nL_d^2(x)},
            $$
            where $L_d(x)$ is the distance between the particles (see Figure 1). Since $L_d(x) = \sqrt{d^2 + x^2}$, we must have that the total pull is given by
            $$
            \begin{aligned}
                F_{\mathrm{total}} &= \lim_{n \to \infty} \lim_{\Delta x \to 0+} \sum \frac{ k Q_1 Q_2 \Delta x }{ n (d^2 + x^2) } \\
                                   &= \lim_{n \to \infty} \int_{-\infty}^{\infty} \frac{k Q_1 Q_2}{n(d^2 + x^2)} dx \\
                                   &= \lim_{n \to \infty} \frac{k Q_1 Q_2}{n} \Bigg[ \frac{1}{d} \arctan(x/d) \Bigg]_{x = -\infty}^{x = \infty} \\
                                   &= \lim_{n \to \infty} \frac{k Q_1 Q_2}{nd} \Bigg[ \frac{\pi}{2} - \Bigg( -\frac{\pi}{2} \Bigg) \Bigg]  \\
                                   &= \lim_{n \to \infty} \frac{\pi k Q_1 Q_2}{nd}.
            \end{aligned}
            $$
            <div style="text-align: center;">
                <img src="ChargedParticle.svg"></img>
            </div>
            <p>
            If $d > 0$, we must have $F_{\mathrm{total}} = 0$. Next, let's see what happens if $d = 0$:
            $$
            \begin{aligned}
                F_{\mathrm{total}} &= \lim_{n \to \infty} \lim_{\Delta x \to 0+} \sum \frac{ k Q_1 Q_2 \Delta x }{ n (d^2 + x^2) } \\
                                   &= \lim_{n \to \infty} \lim_{\Delta x \to 0+} \sum \frac{ k Q_1 Q_2 \Delta x}{nx^2} \\
                                   &= \lim_{n \to \infty} \int_{-\infty}^{\infty} \frac{k Q_1 Q_2}{nx^2} dx \\
                                   &= \lim_{n \to \infty} \frac{k Q_1 Q_2}{n} \Bigg[ -\frac{1}{x} \Bigg]_{x = -\infty}^{x = \infty} \\
                                   &= \lim_{n \to \infty} \lim_{a \to \infty} \frac{k Q_1, Q_2}{n}\Bigg[ -\frac{1}{a} - \Bigg( -\frac{1}{-a} \Bigg) \Bigg] \\
                                   &= \lim_{n \to \infty} \lim_{a \to \infty} \frac{k Q_1, Q_2}{n}\Bigg[ -\frac{2}{a} \Bigg] \\
                                   &= 0.
            \end{aligned}
            $$
            So we conclude that the pull is always zero in this setting.
        </article>

        <a href="#calcforcevector"><h3>Calculating a particle's force vector to a finite rod with finite, constant density</h3></a>
        <article>        
            <p>
            In this post, we will discuss a problem of calculating a force vector from a particle to a finite length rod with constant mass density. Now, let $\rho$ be the constant mass density of the given rod. The rod itself is given by the set of $x$-coordinates within range $[a, b]$. The particle projects to the rod at $x = 0$. The distance between the rod (at $x = 0$) and the particle is $d > 0$. The force vector $\vec{F}$ we seek for consists of two orthogonal force vectors: $\vec{F}_h$ as the horizontal force vector and $\vec{F}_v$ as the vertical force vector ($\vec{F} = \vec{F}_h + \vec{F}_v$). The vectors are defined as $\vec{F}_v = (0, v)$ and $\vec{F}_h = (h, 0)$.
            <img class="figure_style" src="ForceVector.svg" alt="The attraction pull vector."/>

            <p>
            What comes to $\vec{F}_h$, it is defined as
            $$
            h = m\rho \int_a^b \frac{\sin(\arctan(x / d))}{d^2 + x^2} \, \mathrm{d}x.
            $$

            <a href="https://www.wolframalpha.com/input?i=sin%28arctan%28x%2Fd%29%29%2F%28d%5E2+%2B+x%5E2%29">According to WolframAlpha</a>, 
            $$
            \frac{\sin(\arctan(x / d))}{d^2 + x^2} = \frac{x}{(d^2 + x^2) \sqrt{d^2 + x^2}}.
            $$
            Once again, <a href="https://www.wolframalpha.com/input?i=integrate+sin%28arctan%28x%2Fd%29%29%2F%28d%5E2+%2B+x%5E2%29">according to WolframAlpha</a>, 
            $$
            \int \frac{\sin(\arctan(x / d))}{d^2 + x^2} \, \mathrm{d}x = -\frac{1}{\sqrt{d^2 + x^2}}.
            $$
            Next, we derivate the above integral:
            \begin{aligned}
                \frac{\mathrm{d}}{\mathrm{d}x} \Bigg( -\frac{1}{\sqrt{d^2 + x^2}} \Bigg) &= - \frac{ \frac{ \mathrm{d} }{ \mathrm{d}x } \Bigg( d^2 + x^2 \Bigg)^{\frac{1}{2}} }{d^2 + x^2} \\
                                                                                         &= - \frac{\frac{1}{2} \Bigg( d^2 + x^ 2 \Bigg)^{-\frac{1}{2}} 2x}{d^2 + x^2} \\
                                                                                         &= - \frac{x}{(d^2 + x^2) \sqrt{d^2 + x^2}}
            \end{aligned}
            <p>
            Next, we need to deal with $\vec{F_v}$. To this end, we need to calculate
            \begin{aligned}
                v &= -\int_a^b \frac{\cos(\arctan(x/d)) }{d^2 + x^2} \mathrm{d}x \\
                  &= -\int_a^b \frac{ d }{ (d^2 + x^2) \sqrt{d^2 + x^2 } } \mathrm{d}x \\
                  &= -\frac{ x }{ d\sqrt{d^2 + x^2} }
            \end{aligned}

            The derivative of the above integral is given by

            \begin{aligned}
                -\frac{\mathrm{d}}{\mathrm{d}x} \frac{ x }{ d\sqrt{d^2 + x^2} } &= -\frac{d\sqrt{d^2 + x^2} - x \frac{1}{2} d 2x ( d^2 + x^2 )^{-\frac{ 1 }{ 2 }}} { d^2 (d^2 + x^2) } \\
                &= -\frac{1}{d\sqrt{d^2 + x^2}} + \frac{x^2}{d(d^2 + x^2)\sqrt{d^2 + x^2}} \\
                &= -\frac{d^2 +´x^2}{d(d^2 + x^2)\sqrt{d^2 + x^2}} + \frac{x^2}{d(d^2 + x^2)\sqrt{d^2 + x^2}} \\
                &= - \frac{d^2}{d(d^2 + x^2)\sqrt{d^2 + x^2}} \\
                &= - \frac{d}{(d^2 + x^2)\sqrt{d^2 + x^2}},
            \end{aligned}
            as expected. Finally, the force vector in question is 
            $$\vec{F} = \Bigg( \Bigg[ -\frac{m\rho}{\sqrt{d^2 + x^2}} \Bigg]_{x = a}^{x = b}, \Bigg[ -\frac{m\rho x}{d \sqrt{d^2 + x^2}} \Bigg]_{x = a}^{x = b} \Bigg).$$

            Now, let us compute a sample force vector for the rod $x \in [-1, 2]$ $d = 3$ distance away from the particle with $m = \rho = 1$:
            \begin{aligned}
                \vec{F} &= \vec{F}_h + \vec{F}_v \\
                        &= (h, v) \\
                        &= \Bigg( -\frac{1}{ \sqrt{3^2 + 2^2} } + \frac{1}{ \sqrt{3^2 + (-1)^2} }, -\frac{2}{3\sqrt{3^2 + 2^2} } + \frac{-1}{ 3 \sqrt{ 3^2 + (-1)^2 } } \Bigg) \\
                        &= \Bigg( -\frac{1}{ \sqrt{9 + 4} } + \frac{1}{ \sqrt{9 + 1} }, -\frac{2}{3\sqrt{9 + 4} } + \frac{-1}{ 3 \sqrt{ 9 + 1 } } \Bigg) \\
                        &= \Bigg( -\frac{1}{ \sqrt{13} } + \frac{1}{ \sqrt{10} }, -\frac{2}{3\sqrt{13} } + \frac{-1}{ 3 \sqrt{ 10 } } \Bigg) \\
                        &= \Bigg( -\frac{1}{ \sqrt{13} } + \frac{1}{ \sqrt{10} }, -\frac{2}{3\sqrt{13} } - \frac{1}{ 3 \sqrt{ 10 } } \Bigg) \\ 
                        &\approx (0.039, -0.290).
            \end{aligned}

            <p>
                Also, it might be of interest the case where $a = -b$ and $b \rightarrow \infty$:
                \begin{aligned}
                    \vec{F} &= \Bigg( - \frac{m\rho}{ \sqrt{d^2 + b^2} } - \frac{m\rho}{ \sqrt{d^2 + a^2}  } ,  -\frac{m\rho b}{d\sqrt{d^2 + b^2} } + \frac{m\rho a}{d \sqrt{d^2 + a^2}}  \Bigg) \\
                            &= \Bigg( - \frac{m\rho}{ \sqrt{d^2 + b^2} } + \frac{m\rho }{ \sqrt{d^2 + (-b)^2} }, \frac{m\rho(a - b)}{ d \sqrt{d^2 + b^2} }  \Bigg) \\ 
                            &= \Bigg( 0, \frac{-2 m\rho b }{ d \sqrt{d^2 + b^2} }  \Bigg)
                \end{aligned}

                When $b \rightarrow \infty$, $\vec{F} \rightarrow (0, -2m \rho / d).$ Clearly, $\vec{F} \rightarrow (0, -\infty)$ as $d \rightarrow 0+$, and $\vec{F} \rightarrow (0, \infty)$ as $d \rightarrow 0-$.
        </article>
		
	<a href="#rotenergy"><h3>Calculating rotational energy of a disk via integration</h3></a>
	<article>
		<p>
			Let the disk have radius $R > 0$, mass $m > 0$, angular velocity of rotation $\omega > 0$, and the constant density $\rho = m / (\pi R^2)$. Now, consider the area element $\mathrm{d}A = r \, \mathrm{d}r \, \mathrm{d}\alpha$. The mass of that area element is given by 
			$$\mathrm{d}m = \rho \, \mathrm{d}A = \frac{mr \, \mathrm{d}r \, \mathrm{d}\alpha}{\pi R^2}.$$ 
			Next, the energy of that area is given by
			$$\mathrm{d}E = \frac{1}{2} \mathrm{d}mv^2 = \frac{1}{2} \mathrm{d}m(r\omega)^2 = \frac{mr^3 \omega^2  \, \mathrm{d}r \, \mathrm{d}\alpha}{2\pi R^2}.$$

			Finally, the rotational energy is
			\begin{aligned}
E_{rotational} &= \int_0^{2\pi} \int_0^R \mathrm{d}E \\
               &= \int_0^{2\pi} \int_0^R \frac{mr^3 \omega^2 }{2\pi R^2} \, \mathrm{d}r \, \mathrm{d}\alpha\\
               &= \frac{m\omega^2}{2\pi R^2} \int_0^{2\pi} \int_0^R r^3 \, \mathrm{d}r \, \mathrm{d}\alpha \\
               &= \frac{m\omega^2}{2\pi R^2} \int_0^{2\pi} \Bigg[ \frac{1}{4} r^4 \Bigg]_{r = 0}^{r = R} \mathrm{d}\alpha \\
               &= \frac{m\omega^2R^2}{8\pi} \int_0^{2\pi}\mathrm{d}\alpha \\
               &= \frac{m\omega^2R^2}{8\pi} \Bigg[\alpha\Bigg]_{\alpha = 0}^{\alpha = 2\pi} \\
               &= \frac{1}{4}m\omega^2R^2 \\
			   &= \frac{1}{2}I\omega^2.
			\end{aligned}
		</article>
		
		<a href="#riemann_sums"><h3>Riemann sums for proving an integral identity</h3></a>
		<article>
			<p> 
			In this post, we wish to show that $$\int_a^b \int_c^d f(x)g(y) \, \mathrm{d}y \, \mathrm{d}x = \Bigg( \int_a^b f(x) \, \mathrm{d}x \Bigg) \Bigg( \int_c^d g(y) \, \mathrm{d}y \Bigg).$$ 
			To this end, it follows straight from the linearity of integrals. However, if we are not convinced, we can prove it via Riemann sums:
			\begin{aligned}
				\int_a^b \int_c^d f(x)g(y) \, \mathrm{d}y \, \mathrm{d}x &= \lim_{\Delta x \to 0+} \lim_{\Delta y \to 0+} \sum_{i = 0}^{\Big\lceil \frac{b - a}{\Delta x} \Big\rceil} \sum_{j = 0}^{\Big\lceil \frac{d - c}{\Delta y} \Big\rceil} f(a + i \Delta x) g(c + j \Delta y) \Delta x \Delta y \\
					                                                     &= \Bigg( \lim_{\Delta x \to 0+} \sum_{i = 0}^{\Big\lceil \frac{b - a}{\Delta x} \Big\rceil}  f(a + i \Delta x) \Delta x \Bigg) \Bigg( \lim_{\Delta y \to 0+} \sum_{j = 0}^{\Big\lceil \frac{d - c}{\Delta y} \Big\rceil} g(c + j \Delta y) \Delta y \Bigg) \\
																		 &= \Bigg( \int_a^b f(x) \, \mathrm{d}x \Bigg) \Bigg( \int_c^d g(y) \, \mathrm{d}y \Bigg),
			\end{aligned}
			which concludes the proof.
		</article>
		
		<a href="#swing_duration"><h3>Duration of a swing</h3></a>
		<article>
			<p>
			In this post, we will calculate the swing duration of an object fastened to a pole above it. We start from the following figure:
			<p style="text-align: center;"><img src="SwingingObject.png" style="margin-top: -120px; overflow: hidden;"/></p>
			<p style="text-align: justify;">
			
Let $\theta_{\max}$ be the maximum angle. Let the radius be given: $r > 0$. 

Now we know that the total energy equals the maximum potential energy, which is attained when the angle $\theta$ is either $-\theta_{\max}$ or $\theta_{\max}$. Next, the potential energy at the angle of $\theta \in (-\theta_\max, \theta_\max)$ is

$$
\begin{aligned}
E_p^{\theta} &= mgh = mg(r - r\cos \theta) \\
             &= mgr(1 - \cos \theta).
\end{aligned}
$$
Now, the kinetic energy at the angle $\theta$ is given by 
$$
\begin{aligned}
E_k^{\theta} &= E_{p,total} - E_p^\theta \\
             &= mgr(1 - \cos \theta_{\max}) - mgr (1 - \cos \theta) \\
             &= mgr(1 - \cos \theta_{\max} - 1 + \cos \theta) \\
             &= mgr(\cos \theta - \cos \theta_{\max}) \\
             &= \frac{1}{2} mv^2.
\end{aligned}
$$
From above, we have that
$$
gr(\cos \theta - \cos \theta_{\max}) = \frac{1}{2} v^2,
$$
which is identical with
$$
v = \sqrt{2gr(\cos \theta - \cos \theta_{\max})}.
$$
Next, we must have 
$$
\mathrm{d}s = v \mathrm{d}t,
$$
where $\mathrm{d}s = r \mathrm{d}\theta$, and so
$$
\begin{aligned}
\mathrm{d}t &= \frac{\mathrm{d}s}{v} \\
            &= \frac{r\mathrm{d}\theta}{\sqrt{2gr(\cos \theta - \cos \theta_\max)}} \\
            &= \frac{\sqrt{r}\mathrm{d}\theta}{\sqrt{2g(\cos \theta - \cos \theta_\max)}}.
\end{aligned}
$$
Finally, 
$$
\begin{aligned}
T &= \int_{-a}^a \frac{\sqrt{r}\mathrm{d}\theta}{\sqrt{2g(\cos \theta - \cos \theta_\max)}} \\
  &= \sqrt{\frac{r}{2g}} \int_{-a}^a \frac{\mathrm{d}\theta}{\sqrt{\cos \theta - \cos a}} \\
  &\overset{(1)}{=} \sqrt{\frac{r}{2g}} \Bigg[ \frac{2F\Big( \frac{\theta}{2} \Big| \csc^2\Big( \frac{a}{2}\Big) \Big)}{\sqrt{1 - \cos a}}\Bigg]_{\theta = -a}^{\theta = a} \\
  &= \sqrt{\frac{r}{2g}} \Bigg[ \frac{2F\Big( \frac{a}{2} \Big| \csc^2\Big( \frac{a}{2}\Big) \Big)}{\sqrt{1 - \cos a}}\Bigg] - \sqrt{\frac{r}{2g}} \Bigg[ \frac{2F\Big( -\frac{a}{2} \Big| \csc^2\Big( \frac{a}{2}\Big) \Big)}{\sqrt{1 - \cos a}} \Bigg] \\
  &\overset{(2)}{=} \sqrt{\frac{r}{2g}} \frac{4F\Big( \frac{a}{2} \Big| \csc^2\Big( \frac{a}{2} \Big) \Big)}{\sqrt{1 - \cos a}},
\end{aligned}
$$
where $a = \theta_\max \in (0, \pi / 2)$. Above we relied on the following WolframAlpha search results:
<ul>
	<li>(1) <a href="https://www.wolframalpha.com/input?i=int+1%2Fsqrt%28cos+x+-+cos+a%29">Equation 1,</a></li>
	<li>(2) <a href="https://www.wolframalpha.com/input?i=2+*+EllipticF%5Bx%2F2%2C+csc%5E2%28x%2F2%29%5D+%2F+sqrt%281+-+cos+x%29+-+2+*+EllipticF%5B-x%2F2%2C+csc%5E2%28x%2F2%29%5D+%2F+sqrt%281+-+cos+x%29">Equation 2.</a></li>
</ul>
			</p>
		</article>
		
		<a href="#swing_function"><h3>The model for damped oscillator system</h3></a>
		<article>
		    <p>
			Suppose we are given a rod of length $r > 0$ and we attach to one of the ends an object of mass $m > 0$. We attach the opposite end of the rod to a static axis of rotation. Finally, we are given a friction coefficient $\phi$: for an angle $\theta$, the lost energy is $\phi \theta$. Then, we lift a bit the object around its axis such that the angle between the vertical line and the object becomes $\theta_{init}$, and we let it go.
			<p>
			
			Now, the initial total energy is
			$$E_{total} = mgr(1 - \cos \theta_{init})$$.
			The idea is that while the object swings/oscillates, the sum of potential and kinetic energies decrease. What we want to calculate, is the function $A(t)$ returning the angle of the object as the function of time $t$.
			<p>
			We must have:
			<ul>
				<li>$A(0) = \theta_{init},$</li>
				<li>$\lim_{t \to \infty} A(t) = 0.$</li>
			</ul>
			Finally, we came up with this integral/differential equation:
			$$
			\begin{aligned}
				E_{total} &= E_p(t) + E_k(t) + W(t) \\\\
						  &= mgr (1 - \cos A(t)) + \frac{1}{2} mr^2\Bigg( \frac{\mathrm{d}A(t)}{\mathrm{d}t} \Bigg)^2 + \phi \int_0^t \Bigg| \frac{\mathrm{d}A(x)}{\mathrm{d}x} \Bigg| \; \mathrm{d}x. \\
			\end{aligned}
			$$
		</article>
		
		<!--
        <p id="counter_paragraph">
            <span id="view_count_span"></span>
            <script src="viewCounter.js"></script>
            <script type="text/javascript">processViewCounter();</script>
        </p>-->
        </div>
    </body>
</html>
    
