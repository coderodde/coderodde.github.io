<!DOCTYPE html>
<html>
    <head>
        <title>coderodde - weblog</title>
        <style>
            h1, h3 {
                text-align: center;
            }
            
            article {
                font-family: "Times New Roman";
                font-size: 12pt;
                text-align: justify;
            }
            
            #main {
                width: 800px;
                margin: auto;
            }
            
            .lemma_name {
                font-variant: small-caps;
                font-weight: bold;
            }
            
            .exclude_from_lemma_name {
                font-variant: normal;
                font-weight: normal;
            }
            
            .lemma_claim {
                font-weight: bold;
                font-style: italic;
            }
            
            #browser_note {
                width: 350px;
                border: 2px solid black;
                background-color: #ff5555;
                padding: 5px;
                margin: auto;
                font-weight: bold;
                font-size: 10pt;
            }
            
            .sc {
                font-variant: small-caps;
            }
            
            #main {
                overflow-x: scroll;
            }
        </style>
        <link rel="stylesheet" type="text/css" href="algotype_my_config.css">
        <script src="algotype_my.js" type="application/javascript"></script>
        <script>
                Algotype.ALGORITHM_STEP_COMMENT_TAG = "//";
        </script>

    </head>
    <body>
        <div id="main">
            <h1>coderodde's technical weblog</h1>
            <div id="browser_note">For best rendering of formal text, <br/> it is advised to view this page via desktop browsers.</div>
            
            <a href="#mcelp"><h3 id="mcelp">Solving most cost-effective loan problem</h3></a>
            <article>
                <a href="#most-cost-effective-loan-problem.1.introduction"><h4 id="most-cost-effective-loan-problem.1.introduction">1 Introduction</h4></a>
                <p>
                In the most cost-effective loan problem, we are given a directed
                graph of actors where each actor may lend some amount of resources
                it possesses to its child nodes. In case an actor needs more than
                his immediate parents can lend, the parents might need to lend from
                their parents, adjust the interest rate to cover their own expenses,
                and pass the funds to the original lending actor.
                </p>
                
                <p>
                Formally, we are given a directed graph $G = (V, A)$, where $V$
                is the set of actors, and 
                $A \subseteq V^2 \setminus \{ (u, u) \in V^2 \text{ for all } u \in V\}$ is the set of directed
                arcs, excluding self-loops. By $V(G)$ we denote the actor set of $G$, and likewise, by
                $A(G)$ we denote the arc set of $G$. Given an arc $(u, v) \in A$,
                we call $u$ a <i>parent</i> of $v$, $v$ a <i>child</i> of $u$. 
                Existence of such an arc indicates that $u$ may lend some or all
                of its resources to $v$. Along the graph, we are given a
                <i>potential function</i> $\mathfrak{P} \colon V \to [0, \infty) = \mathbb{R}_{\geq 0}$
                that maps each actor in the graph to the (non-negative) equity that that very
                node has at its disposal. Finally, we are given an <i>interest rate function</i>
                $\mathfrak{I} \colon A \to \mathbb{R}_{\geq 0}$ that maps each arc
                $(u, v) \in A$ to the interest rate the actor $u$ can offer $v$
                when $v$ decides to lend from $u$. From now on, we will call the
                aforementioned amount of resources or equity simply <i>potential</i>.
                </p>
                
                <p>
                Apart from the target data structure, in a problem instance, we
                are given an actor $a \in V$ that applies for a loan, a required
                potential $P \in \mathbb{R}_{\geq 0}$ and a maximum tolerable 
                interest rate $i \in \mathbb{R}_{\geq 0}$. Our aim, then, is to 
                compute a loan (which may involve more than one lending actor) 
                with minimized interest rates.
                </p>
                
                <a href="#most-cost-effective-loan-problem.2.interest-rate-model"><h4 id="most-cost-effective-loan-problem.2.interest-rate-model">2 Interest rate model</h4></a>
                
                <p>
                Throughout the post, we assume a simple interest rate model. The
                accumulated balance at time $t$ since the time point at which the
                loan was issued, with initial principal $\mathfrak{A}$ and interest
                rate $r$ is given by
                \[
                \mathfrak{A}(1 + r)^t.
                \]
                If we have in the graph, for instance, a directed acyclic path 
                $\langle u, v, z \rangle$ with $r_{u,v}$ being the interest rate
                of $(u, v)$, and $r_{v, z}$ being the interest rate of $(v, z)$,
                the interest rate equation becomes
                \[
                \mathfrak{A}(1 + r_{u,v})^t (1 + r_{v,z})^t = \mathfrak{A}\big[ (1 + r_{u,v})(1 + r_{v,z}) \big]^t = \mathfrak{A}(1 + R)^t.
                \]
                Above, $R$ is the <i>combined</i> interest rate. Dividing both 
                sides by $\mathfrak{A}$ and taking $t$-th root, we obtain
                \begin{aligned}
                    (1 + r_{u,v})(1 + r_{v,z}) &= 1 + R \\
                    R + 1 &= 1 + r_{u,v} + r_{v,z} + r_{u,v}r_{v,z} \\
                    R &= r_{u,v} + r_{v,z} + r_{u,v}r_{v,z}. 
                \end{aligned}
                In general, we write $r_1 + r_2 + r_1 r_2 = \mathfrak{C}(r_1, r_2).$ 
                
                </p>
                
                <p>
                Since we may deal with entire &quot;loan chains,&quot; we need 
                to define the concept of <i>effective interest rate</i>.
                Effective interest rate is given by 
                \[
                    I(u, v) = \min \Bigg( \mathfrak{I}(u, v), 
                        \underset{z \in {\rm P{\small ARENTS}}(G, v)}{\mathfrak{C}(\mathfrak{I}(z, v), I(u, z)) } 
                        \Bigg)
                \]
                where ${\rm C{\small HILDREN}}(G, z)$ is the set of child nodes
                of $z$, or, formally, $\{ u \colon (z, u) \in A(G) \}.$ 
                Also, for the above formula to work, we need to set $\mathfrak{I}(u, v) = \infty$ for all missing arcs $(u, v) \not\in A(G)$.
                </p>
                
                <a href="#most-cost-effective-loan-problem.3.problem-statement"><h4 id="most-cost-effective-loan-problem.3.problem-statement">3 Problem statement</h4></a>
                <p>
                Given a problem instance $(G, a, \mathfrak{P}, \mathfrak{I}, P, i)$,
                we wish to compute two additional functions: $\pi$ and $d$.
                $\pi \colon V \to \mathbb{R}_{\geq 0}$ is called a 
                <i>solution potential function</i> and it maps each actor 
                $u$ to potential $\pi(u)$ $u$ can lend, and $d \colon V \to V$
                is called a <i>direction function</i> and it maps each actor
                $u$ to some of its children $d(u)$ to which $\pi(u)$ worth 
                potential is being lent. What comes to constraints, no actor
                $u$ lending some of its potential shall have $I(u, a) > i$,
                since $a$ cannot afford effective interest rates above $i$.
                Also, if it is not possible, due to the first constraint, to
                obtain a loan worth $P$, the loan should be maximized from below
                as close to $P$ as possible.
                </p>
                
                <p>
                In order to implement the first constraint, we need to define the
                set of <i>admissible</i> solution potential functions:
                \[
                \pi_{I, a, i, G} = \{ \pi \colon V(G) \to \mathbb{R}_{\geq 0} \; | \; \pi(u) = 0 \text{ if } I(u, a) > i \}.
                \]
                An admissible solution potential function $\pi$ is said to be <i>valid</i>
                if it also satisfies
                \[
                    \sum_{u \in V} \pi(u) \in [0, P],
                \]
                and we denote that by $\pi \in \mathfrak{V}$.
                </p>
                
                <p>
                Now, we can state the objective formally:
                \[
                \pi = \underset{\pi' \in \mathfrak{V}}{\arg \min}{\Bigg[ P - \sum_{u \in V} \pi'(u) \Bigg]},
                \]
                and
                \[
                d(u) = \underset{z \in {\rm C {\small HILDREN}}(G, u)}{\arg \min} \Bigg[\mathfrak{C}\big(\mathfrak{I}(u, z), I(z, a)\big)\Bigg].
                \]
                </p>
                
                <a href="#most-cost-effective-loan-problem.4.solution-algorithm"><h4 id="most-cost-effective-loan-problem.4.solution-algorithm">4 Solution algorithm</h4></a>
                <p>
                Since the effective interest rate does not decrease with adding
                more directed arcs, we must have that for any actor $a \in V$ the
                most cost-efficient lender is an immediate parent. Whether the second most cost-efficient lender
                is an immediate parent or not depends on effective interest rates.
                Regardless, since we consider effective interest rates, basically we 
                are growing a directed &quot;minimum spanning tree&quot; which we
                extend in a greedy fashion one arc at a time:
                In the very beginning, the tree is trivial and consists only of $a$.
                Then a most cost-effective parent $u_1$ is selected and the arc $(u_1, a)$
                is introduced to the tree. Then $u_2$ is selected. It must not
                belong to $\{a, u_1\}$ while have the lowest possible effective rate
                among all nodes in $V \setminus \{ a, u_1 \}$. This procedure continues
                until a desired potential $P$ is collected or until there is no more nodes 
                left with affordable effective interest rates. Below 
                <span style="font-variant: small-caps; font-weight: bolder;">Priority-Queue-Insert</span>$(Q, \langle a, b, c \rangle)$
                stores the triple $\langle a, b, c \rangle$ in the priority queue $Q$ and uses $c$ as a priority key.
                </p>
                <p>
                    <alg-algorithm header="Most-Cost-Effective-Loans$(G, a, \mathfrak{P}, \mathfrak{I}, P, i)$"
                                   algorithm-upper-header-class="upper_header_bar"
                                   algorithm-lower-header-calss="lower_header_bar"
                        algorithm-footer-class="footer_bar">
                        <alg-step>$\text{let } Q \text{ be an empty priority queue}$</alg-step>          
                        <alg-step>$\text{let } \pi \text{ be an empty solution potential function}$</alg-step>          
                        <alg-step>$\text{let } d \text{ be an empty direction function}$</alg-step>          
                        <alg-step>$C \leftarrow \emptyset$</alg-step>          
                        <alg-step>$P_{\text{collected}} \leftarrow 0$</alg-step>
                        <alg-foreach condition="$u \in V(G)$">
                            <alg-step>$\pi(u) \leftarrow 0$</alg-step>
                            <alg-step>$d(u) \leftarrow \Nil$</alg-step>
                        </alg-foreach>
                        <alg-foreach condition="$u \in $ Parents$(G, a)$">
                            <alg-if condition="$\mathfrak{I}(u, a) \leq i$">
                                <alg-step>Priority-Queue-Insert$(Q, \langle u, a, \mathfrak{I}(u, a) \rangle)$</alg-step>
                            </alg-if>
                        </alg-foreach>
                        <alg-while condition="$|Q| > 0 \; \And \; P_{\text{collected}} < P$">
                            <alg-step>$\langle u, v, i_{\text{current}} \rangle \leftarrow $ Priority-Queue-Extract-Minimum$(Q)$</alg-step>
                            <alg-step>$p_\Delta \leftarrow \min (P - P_{\text{collected}}, \mathfrak{P}(u))$</alg-step>
                            <alg-step>$P_{\text{collected}} \leftarrow P_{\text{collected}} + P_\Delta$</alg-step>
                            <alg-step>$\pi(u) \leftarrow P_\Delta$</alg-step>
                            <alg-step>$d(u) \leftarrow v$</alg-step>
                            <alg-step>$C \leftarrow C \cup \{ u \}$</alg-step>
                            <alg-foreach condition="$z \in$ Parents$(G, u)$">
                                <alg-if condition="$z \not \in C$">
                                    <alg-step>$i_{\text{next}} \leftarrow \mathfrak{C} \big( i_{\text{current}}, \mathfrak{I}(z, u) \big)$</alg-step>
                                    <alg-if condition="$i_{\text{next}} \leq i$">
                                        <alg-step>Priority-Queue-Insert$(Q, \langle z, u, i_{\text{next}}\rangle)$</alg-step>
                                    </alg-if>
                                </alg-if>
                            </alg-foreach>
                        </alg-while>
                        <alg-return>$(\pi, d)$</alg-return>
                    </alg-algorithm>
                </p>
                
                <a href="#most-cost-effective-loan-problem.5.proof-of-correctness"><h4 id="most-cost-effective-loan-problem.5.proof-of-correctness">5 Proof of correctness</h4></a>
                <p>
                <span class="lemma_name">Lemma 1 (Termination)</span>
                <span class="lemma_claim">The algorithm terminates.</span><br/>
                Note that each node removed from the priority queue at line 13 is
                inserted into the closed set $C$ at line 18. Now, the line 23 will not
                reintroduce the same node to $Q$ and so, $Q$ eventually becomes empty (unless
                the algorithm terminates earlier in case the required potential is collected).
                </p>
                <p>
                <span class="lemma_name">Lemma 2 (Optimality)</span>
                <span class="lemma_claim">The algorithm finds most cost-effective loans.</span><br/>
                The effective interest rate function $I$ implicitly defines a transitive closure
                from any actor $u \neq a$ to $a$ assuming the effective interest rate of $u$ is
                within the constraint $I(u, a) \leq i$. That way, $a$ loans from all affordable
                parents (immediate or intermediate) in a greedy fashion: lend as much as possible
                from the most affordable actor, then lend as much as possible from the second most
                affordable actor, and so on until the requested potential is collected or there are
                no more affordable lenders left. It is easy to see that such strategy minimizes
                interest expenses.
                </p>
                <p>
                <span class="lemma_name">Lemma 3 (<span class="exclude_from_lemma_name">$d$</span> is acyclic)</span>
                <span class="lemma_claim">Given a solution direction function $d$, 
                there exist no actor sequence $\langle u_1, u_2, \dots, u_k \rangle$
                such that $d(u_1) = u_2$, $d(u_2) = u_3$, $\dots$, $d(u_{k - 1}) = u_k$ and $d(u_k) = u_1$.</span><br/>
                The only way for such a cycle to emerge is to have $\mathfrak{I}(u_1, u_2) =
                \mathfrak{I}(u_2, u_3) = \dots = \mathfrak{I}(u_{k-1}, u_k) = \mathfrak{I}(u_k, u_1) = 0$.
                Without loss of generality, suppose the search enters the cycle via $u_1$. When $u_k$ will be
                removed from the priority queue, the arc $(u_k, u_1)$ will be ignored by the line 20 since $u_1$ is in $C$, and
                so, there is no way $d(u_k)$ could be mapped to $u_1$.
                </p>
                <p>
                <span class="lemma_name">Lemma 4</span>
                <span class="lemma_claim">The sum of all solution potentials cannot exceed $P$.</span><br/>
                This is trivially guaranteed by the line 14 and the second test at line 12.
                </p>
                
                <a href="#most-cost-effective-loan-problem.6.running-time-analysis"><h4 id="most-cost-effective-loan-problem.6.running-time-analysis">6 Running time analysis</h4></a>
                <p>
                All the operations except <span class="sc"><b>Priority-Queue-Insert</b></span>
                and <span class="sc"><b>Priority-Queue-Extract-Minimum</b></span> run in $\mathcal{O}(1)$ time.
                In particular, operations on $\pi, d$ and $C$ may be expected to run in $\mathcal{O}(1)$
                on average by resorting to hash-table based maps and sets. With geometric expansion
                scheme <a href="#ref1"><b>[1]</b></a>, adding an element to a hash-table based data
                structure runs in <b>amortized</b> $\mathcal{O}(1)$. (If the load factor reaches its
                upper bound, the underlying storage array must be made larger.)
                </p>
                <p>
                What comes to the priority queue $Q$, it clearly stores graph actors without copies
                of a same actor. Now, if we choose a binary heap, both run in $\mathcal{O}(\log V)$ time.
                <span class="sc"><b>Priority-Queue-Insert</b></span> is called no more than $|E|$
                times, and <span class="sc"><b>Priority-Queue-Extract-Minimum</b></span> is called once per
                node, and so we have the running time $\mathcal{O}(E \log V + V \log V) = \mathcal{O}(E \log V)$. By deploying 
                a Fibonacci heap instead, we may reduce this to $\mathcal{O}(E + V \log V)$.
                </p>
                
                <a href="#most-cost-effective-loan-problem.7.future-work"><h4 id="most-cost-effective-loan-problem.7.future-work">7 Future work</h4></a>
                We used a very simple interest rate model in our solution, and
                so it leaves the case where the used interest rate model is more
                realistic. In general, with initial principal $\mathfrak{A}$,
                interest rate $r > 0$, the number of compound periods $n$ per time unit, and time 
                since the moment the loan was issued $t$, the balance grows 
                according to 
                \[
                    \mathfrak{C} = \mathfrak{A}\Bigg( 1 + \frac{r}{n} \Bigg)^{\lfloor nt \rfloor}.
                \]
                Also, as $n \to \infty$, $\mathfrak{C} \to \mathfrak{A}e^{rt}$.
                Combining loans with different parameters in a meaningful way 
                seems to be a non-trivial task but we might address it later.
                
                <a href="#most-cost-effective-loan-problem.8.references"><h4 id="most-cost-effective-loan-problem.8.references">8 References</h4></a>
                <b>[1]</b> <a id="ref1" target="_blank" href="https://coderodde.wordpress.com/2015/08/01/keeping-vectors-efficient/">Keeping vectors efficient</a> (Retrieved 2018-03-09.)
            </article>
            
            <a href="#inclusion-exclusion-principle"><h3 id="inclusion-exclusion-principle">Proving inclusion-exclusion principle</h3></a>
            
            <article>
                <p>It is easy to check pictorially using a Venn diagram that given two sets, $A_1$ and $A_2$, $|A_1 \cup A_2| = |A_1| + |A_2| - |A_1 \cap A_2|$. 
                   The <b>inclusion-exclusion principle</b> generalizes the previous identity to a collection of sets $A_1, A_2, \dots, A_n$, and is given by</p>
                \begin{aligned}
                    \Bigg\vert \bigcup_{i = 1}^n A_i \Bigg\vert = \sum_{i = 1}^n (-1)^{i + 1} \Bigg(\sum_{1 \leq k_1 < \dots < k_i \leq n}\Bigg\vert  \bigcap_{j = 1}^i A_{k_j}  \Bigg\vert\Bigg).
                \end{aligned}
                <p>We will use induction to prove also any case $n > 2$. Let $B = \bigcup_{i = 1}^n A_i$, and $A_{n + 1}$ given. Using the same principle for the case of only two sets, we must have
                \[
                    |B \cup A_{n + 1}| = |B| + |A_{n + 1}| - |B \cap A_{n + 1}|.
                \]
                Next, we need a simple lemma for extending distributive law to multiple sets:
                </p> 
                <p>
                    <span class="lemma_name">Lemma 1 (Distributive law for multiple sets)</span>
                    <span class="lemma_claim">For any sets $A_1, \dots, A_n, B$, we must have
                    $$
                    \Bigg( \bigcup_{i = 1}^n A_i \Bigg) \cap B = \bigcup_{i = 1}^n (A_i \cap B).
                    $$
                    </span><br/>
                    First, let us verify the base case $n = 2$:
                    \begin{aligned}
                    \Bigg( \bigcup_{i = 1}^2 A_i \Bigg) \cap B &= (A_1 \cup A_2) \cap B \\
                                                               &= (A_1 \cap B) \cup (A_2 \cap B) && \text{by distributive law}\\
                                                               &= \bigcup_{i = 1}^2 (A_i \cap B).
                    \end{aligned}
                    
                    Suppose the identity holds for $A_1, \dots, A_n$. Now, 
                    \begin{aligned}
                    \Bigg( \bigcup_{i = 1}^{n + 1} A_i \Bigg) \cap B &= \Bigg[ \Bigg( \bigcup_{i = 1}^n A_i \Bigg) \cup A_{n + 1} \Bigg] \cap B \\
                                                                     &= \Bigg[ \Bigg( \bigcup_{i = 1}^n A_i \Bigg) \cap B \Bigg] \cup \Bigg[ A_{n + 1} \cap B \Bigg] && \text{by distributive law}\\
                                                                     &= \Bigg[ \bigcup_{i = 1}^n (A_i \cap B) \Bigg] \cup \Bigg[ A_{n + 1} \cap B \Bigg] && \text{by induction hypothesis} \\
                                                                     &= \bigcup_{i = 1}^{n + 1} (A_i \cap B)
                    \end{aligned}
                    as desired. Now
                    \begin{aligned}
                        \Bigg\lvert \bigcup_{i = 1}^{n + 1} A_i \Bigg\rvert &= \Bigg\lvert \Bigg( \bigcup_{i = 1}^n A_i \Bigg) \cup A_{n + 1} \Bigg\rvert \\
                                                                            &= \Bigg\lvert \bigcup_{i = 1}^n A_i \Bigg\rvert + \Bigg\lvert A_{n + 1} \Bigg\rvert - \Bigg\lvert \Bigg( \bigcup_{i = 1}^n A_i \Bigg) \cap A_{n + 1}\Bigg\rvert\\
                                                                            &= \Bigg\lvert \bigcup_{i = 1}^n A_i \Bigg\rvert + \Bigg\lvert A_{n + 1} \Bigg\rvert - \Bigg\lvert \bigcup_{i = 1}^n (A_i \cap A_{n + 1}) \Bigg\rvert \quad \text{by distributive law} \\
                         &= \sum_{i = 1}^n (-1)^{i + 1} \Bigg(\sum_{1 \leq k_1 < \dots < k_i \leq n}\Bigg\vert  \bigcap_{j = 1}^i A_{k_j}  \Bigg\vert\Bigg) \quad \text{by induction hypothesis} \\
                         &+ \vert A_{n + 1} \vert - \sum_{i = 1}^n (-1)^{i + 1} \Bigg( \sum_{1 \leq k_1 < \dots k_i\leq n} \Bigg\vert \bigcap_{j = 1}^i (A_{k_j} \cap A_{n+1})\Bigg\vert \Bigg) \\
                         
                         &= \vert A_{n + 1} \vert - \sum_{i = 1}^n (-1)^{i + 1} \Bigg( \sum_{1 \leq k_1 < \dots k_i\leq n} \Bigg\vert \bigcap_{j = 1}^i (A_{k_j} \cap A_{n+1})\Bigg\vert \Bigg) \\
                         
                         &+ \lvert A_{n + 1} \rvert - \Bigg[ \sum_{i = 1}^n | A_i \cap A_{n + 1} | - \sum_{1 \leq i < j \leq n} \lvert (A_i \cap A_{n + 1}) \cap (A_j \cap A_{n + 1}) \rvert + \dots + (-1)^n \sum_{1 \leq x_1 < x_2 < \dots x_{n - 1} \leq n} \lvert (A_{x_1} \cap A_{n + 1}) \cap \dots \cap (A_{x_{n - 1}} \cap A_{n + 1}) \rvert + (-1)^{n + 1} \Bigg\lvert \bigcap_{i = 1}^n (A_i \cap A_{n + 1}) \Bigg\rvert\Bigg] \\
                         &= \sum_{i = 1}^n \lvert A_i \rvert - \sum_{1 \leq i < j \leq n} \lvert A_i \cap A_j \rvert + \sum_{1 \leq i < j < k \leq n} \lvert A_i \cap A_j \cap A_k \rvert + \dots + (-1)^{n + 1} \lvert A_1 \cap \dots \cap A_n\rvert \\
                         &+ \lvert A_{n + 1} \rvert - \Bigg[ \sum_{i = 1}^n \lvert A_i \cap A_{n + 1} \rvert - \sum_{1 \leq i < j \leq n} \lvert A_i \cap A_j \cap A_{n + 1} \rvert + \dots + (-1)^n \sum_{1 \leq x_1 < x_2 < \dots < x_{n - 1} \leq n} \lvert A_{x_1} \cap A_{x_2} \dots A_{x_{n - 1}} \cap A_{n + 1} \rvert + (-1)^{n + 1} \Bigg\lvert \bigcap_{i = 1}^{n + 1} A_i \Bigg\rvert \Bigg] \\
                         &= \sum_{i = 1}^{n + 1} \lvert A_i \rvert - \sum_{1 \leq i < j \leq n + 1} \lvert A_i \cap A_j \rvert + \sum_{1 \leq i < j < k \leq n + 1} \lvert A_i \cap A_j \cap A_k \rvert + \dots + (-1)^{n + 2} \Bigg\lvert \bigcap_{i = 1}^{n + 1} A_i \Bigg\rvert.
                    \end{aligned}
                </p>
            </article>
            
            <a href="#mcelp"><h3 id="bdfid">Richard E. Korf's bidirectional depth-first iterative deepening pathfinding algorithm</h3></a>
            <article>
                
                
                <p>
                In this post, I will briefly discuss a rather simple graph search technique that turned out to be rather efficient on sparse, directed, unweighted graphs. 
                Before that, I will review some terminology. 
                A directed, unweighted graph $G$ is an ordered pair $(V, A)$, where $V$ is the set of <i>nodes</i>, and $A \subseteq V \times V$ is the set of directed <i>arcs</i>.
                Given two terminal nodes $s, t \in V$, we wish to find a <i>shortest</i> path, or, in other words, a path that connects $s$ to $t$ using minimum number of arcs.
                According to common jargon, $s$ is called a source node, and $t$ is called a target node. Also, by $A(G)$ we will denote the arc set of $G$.
                Also, if we are given an arc $a = (u, v)$, we call $u$ a <i>parent</i> of $v$, $v$ a <i>child</i> of $u$. 
                Finally, we reserve the term &quot; search frontier&quot; to depict the set of nodes no further from the main node than $\Delta \in \mathbb{N} \cup \{ 0 \}$ steps.
                </p>
                
                <p>
                What comes to actual algorithm in question, it utilizes iterative deepening in order to reduce the memory consumption. 
                It first checks that the invocation is trivial (the source node is the target node), and if so, returns $\langle t \rangle$. 
                Let $F_f^k$ be the set of nodes in $G$ that are reachable from $s$ along the arcs.
                Let also $F_b^k$ be the set of nodes in $G$ tat are reachable from $t$ along the arcs in <b>opposite</b> direction.
                Formally, the algorithm computes $F_f^k$ and $F_b^k$. As soon as the two sets intersect, we have found a shortest path.
                Otherwise, $k$ is incremented, and the search repeats once again. There is, however, a catch: suppose a gimple graph $V = \{s, u_1, u_2, t\}, A = \{ (s, u_1), (u_1, u_2), (u_2, t) \}$ is searched for a shortest path.
                Now, the search procedure currently under discussion will return with no path, and that happens because when the forward search
                
                Otherwise, the algorithm checks to see whether any child of $s$ is $t$. If not, visit all the parents of $t$; call that 
                </p>
                
                <p>
                In this post, I will briefly discuss a rather simple graph search technique that turned out to be rather efficient and consumes a moderate amount of memory. 
                The algorithm in question combines bidirectional search with iterative deepening. Bidirectionality buys us time-wise efficiency, whereas iterative deepening approach helps us save some memory. In this instance, we work on directed, unweighted graphs. In traditional, unidirectional breadth-first search, the work done is
                \[
                W_1 = \sum_{i = 0}^N d^i,
                \]
                where $N$ is the number of arcs on the shortest path, and $d$ is the average out-degree. Of course, the above expression requires little variance in node out-degrees. If, however, we denote the average out-degree by $d_o$, and average in-degree by $d_i$, the work done by bidirectional breadth-first search is 
                \[
                W_2 = \sum_{j = 0}^{N / 2} d_i^j + \sum_{j = 0}^{N / 2} d_o^j.
                \]
                Now, if we set $d_i = d_o = d$, the speedup is roughly 
                \begin{aligned}
                \frac{W_1}{W_2} = \frac{\sum_{j = 0}^N d^j}{2 \sum_{j = 0}^{N / 2} d^j}
                                = \frac{\frac{1 - d^{N + 1}}{1 - d}}{2 \frac{1 - d^{N / 2 + 1}}{1 - d}}
                                = \frac{1 - d^{N + 1}}{2 (1 - d^{N / 2 + 1})}
                                =\frac{d^{N + 1} - 1}{2(d^{N / 2 + 1} - 1)}
                                \approx \frac{d^{N + 1}}{2d^{N / 2 + 1}}
                                = \frac{d^{N / 2}}{2}
                                = \frac{\sqrt{d}^N}{2}
                                = \Theta(d^N),
                \end{aligned}
                which implies exponential speedup in shortest path length.
                </p>
                
                <p>
                The bidirectional iterative deepening search works as follows. If the source node is the target node, halt and return a list containing only the node in question.
                Otherwise, scan the child nodes of the source node, and scan the parent nodes of the target node. If there is a node scanned twice, we have found a shortest path.
                If that does not produce a shortest path, go two steps deeper in both search directions starting from source and target nodes. There is, however, a catch: this arrangement may return with no solution in case the shortest path consists of an odd number of arcs. 
                To remedy this, for each depth $\Delta$, the forward search goes one step deeper. 
                
               
                </p>
                
                <p align="center">
                    <img src="BID1.png" width="400px"/>
                </p>
                
                <p>
                    The figures <b>1 (A)</b> and <b>1 (B)</b> demonstrate how the two search spaces go "through" each other, and the figure <b>1 (C)</b> shows how to address that issue.
                </p>
                
                <p>
                    Before we proceed to pseudocode, we have to review some notational conventions. A directed graph $G$ is a tuple $(V, A)$, where $V$ is a set of nodes, and $A \subseteq V^2$ is a set of directed arcs. 
                    Given such a graph $G$, we denote its arc set by $A(G)$. In addition, $\{ n \colon (u, n) \in A(G) \}$ is simply a set of children of the node $u$. Analogously, 
                    $\{ n \colon (n, u) \in A(G) \}$ is the set of parent nodes of $u$. As a reminder, given a directed arc $(u, v) \in A(G)$, we consider it as an arrow from $u$ to $v$, and we call $u$ a <i>parent</i> of $v$, and $v$ a <i>child</i> of $u$.
                </p>
                
                <p>
                    <alg-algorithm header="Build-Path($s, \mu, B, G$)"
                                   algorithm-upper-header-class="upper_header_bar"
                                   algorithm-lower-header-class="lower_header_bar"
                                   algorithm-footer-class="footer_bar">
                        <alg-step>$\pi \leftarrow$ Find-Shortest-Path$(G, s, \mu)$</alg-step>
                        <alg-step>$\text{remove the last node from } \pi$</alg-step>
                        <alg-return>$\pi \circ B$</alg-return>
                    </alg-algorithm>
                </p>
                
                <p>
                    <alg-algorithm header="Depth-Limited-Search-Forward$(G, u, \Delta, F)$"
                                   algorithm-upper-header-class="upper_header_bar"
                                   algorithm-lower-header-class="lower_header_bar"
                                   algorithm-footer-class="footer_bar">
                        <alg-if condition="$\Delta = 0$">
                            <alg-step>$F \leftarrow F \cup \{ u \}$</alg-step>
                            <alg-return></alg-return>
                        </alg-if>
                        <alg-foreach condition="$v \in \{ n \colon (u, n) \in A(G)\}$">
                            <alg-step>Depth-Limited-Search-Forward$(G, v, \Delta - 1, F)$</alg-step>
                        </alg-foreach>
                    </alg-algorithm>
                </p>
                
                <p>
                    <alg-algorithm header="Depth-Limited-Search-Backward$(G, u, \Delta, B, F)$"
                                   algorithm-upper-header-class="upper_header_bar"
                                   algorithm-lower-header-class="lower_header_bar"
                                   algorithm-footer-class="footer_bar">
                        <alg-step>$\text{prepend } u \text{ to } B$</alg-step>
                        <alg-if condition="$\Delta = 0$">
                            <alg-if condition="$u \in F$">
                                <alg-return>$u$</alg-return>
                            </alg-if>
                            <alg-step>$\text{remove the first node in }B$</alg-step>
                            <alg-return>$\Nil$</alg-return>
                        </alg-if>
                        <alg-foreach condition="$v \in \{ n \colon (n, u) \in A(G) \}$">
                            <alg-step>$\mu \leftarrow $Depth-Limited-Search-Backward$(G, v, \Delta - 1, B, F)$</alg-step>
                            <alg-if condition="$\mu \neq \Nil$">
                                <alg-return>$\mu$</alg-return>
                            </alg-if>
                        </alg-foreach>
                        <alg-step>$\text{remove the first node in } B$</alg-step>
                        <alg-return>$\Nil$</alg-return>
                    </alg-algorithm>
                </p>
                
                
                <p>
                    <alg-algorithm header="Find-Shortesst-Path($G, s, t$)"
                                   comment="The main search routine"
                                   algorithm-upper-header-class="upper_header_bar"
                                   algorithm-lower-header-class="lower_header_bar"
                                   algorithm-footer-class="footer_bar">
                        <alg-if condition="$s = t$">
                            <alg-return>$\langle s \rangle$</alg-return>
                        </alg-if>
                        <!--<alg-if condition="$t \in \{ u \colon (s, u) \in A(G) \}$" comment="$t$ is child of $s$">
                            <alg-return>$\langle s, t \rangle$</alg-return>
                        </alg-if>-->
                        <alg-step>$\Delta \leftarrow 0$</alg-step>
                        <alg-step>$F, F_{\text{prev}}, B \leftarrow \emptyset$</alg-step>
                        <alg-forever>
                            <alg-step>Depth-Limited-Search-Forward$(G, s, \Delta, F)$</alg-step>
                            <alg-if condition="$F = F_{\text{prev}}$">
                                <alg-return comment="No path from $s$ to $t$">$\Nil$</alg-return>
                            </alg-if>
                            <alg-step>$F_{\text{prev}} = F$</alg-step>
                            <alg-foreach condition="$d = \Delta, \Delta + 1$">
                                <alg-step>$\mu \leftarrow $ Depth-Limited-Search-Backward$(G, t, d, B, F)$</alg-step>

                                <alg-if condition="$\mu \neq \Nil$">
                                    <alg-return>Build-Path$(s, \mu, B, G)$</alg-return>
                                </alg-if>

                                <alg-step>$B \leftarrow \emptyset$</alg-step>
                                
                            </alg-foreach>
                            <alg-step>$F \leftarrow \emptyset$</alg-step>
                            <alg-step>$\Delta \leftarrow \Delta + 1$</alg-step>
                        </alg-forever>
                    </alg-algorithm>
                </p>
                
                <p>
                    The results are rather impressive. What comes to solving 15-puzzles, while iterative deepening A* dominates BID by a factor of three or so, on general graphs, BID 
                    is faster than iterative deepening depth-first search by an order of magnitude, and BID outperforms unidirectional breadth-first search by three orders
                    of magnitude. The following listing is a typical output of the benchmarking program:
                <pre>
                    <code>
*** 15-puzzle graph benchmark ***
Seed = 1544375493597
BreadthFirstSearch in 1050 milliseconds. Path length: 18
IterativeDeepeningDepthFirstSearch in 36302 milliseconds. Path length: 18
BidirectionalIterativeDeepeningDepthFirstSearch in 20 milliseconds. Path length: 18
IterativeDeepeningAStar in 116 milliseconds. Path length: 18
Algorithms agree: true

*** General graph benchmark ***
Seed = 1544375531134
BidirectionalIterativeDeepeningDepthFirstSearch in 0 milliseconds. Path length: 5
IterativeDeepeningDepthFirstSearch in 10 milliseconds. Path length: 5
BreadthFirstSearch in 472 milliseconds. Path length: 5</code>
                </pre>
                </p>
            </article>
            
            <a href="#on_radial_area"><h3 id="on_radial_area">Computing radial sets with overlapping areas</h3></a>
            <article>
                <p  >
                    In this post, we shall compute the radial sets without overlapping areas in polar coordinates.
                    A function $r = f(\theta)$ is said to be <i>monotonically reducing</i> on the interval $I = [a, b]$, if
                    we have $f(\theta) \geq f(\theta + 2\pi)$ for any $\theta \in [a, b - 2\pi]$. Now, the radial set is calculated as
                    \[
                        A = \frac{1}{2} \int_a^b f^2(\theta) \, d\theta,
                    \]
                    if $b - a \leq 2\pi$. In case $b - a > 2\pi$, some of the area will overlap. We can, however, deal with that issue:
                    \begin{align}
                    A = \frac{1}{2} \Bigg[ \int_a^{a + 2\pi} f^2(\theta) \, d\theta - 
                        \sum_{k = 1}^{\lfloor (\beta - \alpha) / 2\pi - 1 \rfloor} \int_{\alpha + 2\pi k}^{\alpha + 2\pi (k + 1)} f^2(\theta) \, d\theta 
                        - \int_{\alpha + 2\pi + 2\pi \lfloor (\beta - \alpha - 2\pi) / 2\pi \rfloor}^{\beta} f^2(\theta) \, d\theta,   
                    \Bigg].
                    \end{align}
                </p>
            </article>
            <h3>Rotating a parabola</h3>
            <article>
                <p>
                In this post, we will investigate how to rotate a parabola $P$ in a plane. 
                Let $V = (x_V, y_V)$ be the vertex of $P$ and $\alpha$ be the angle in radians between axis of symmetry 
                and the axis parallel to the $x$-axis $(y = y_V)$, call it $\ell$. As the value of $\alpha$ grows, $P$ rotates counter-clockwise direction.
                Finally, we are given a parameter $\beta$, which defines geometry of $P$, $\beta t^2$. When 
                $\alpha = 0$, $P$ opens upwards. When $\alpha = \pi / 2$, $P$ opens to the left.
                What we wish to accomplish is to find out how to rotate the parabola around their vertices.
                </p>
                
                <p>
                Next, we need a way to calculate the position and slope of a tangent line (call it $T$) visiting $V$ such that it makes an angle of $\alpha$ radians with $\ell$.
                </p>
                
                <p>
                    \begin{align}
                    \frac{y - y_V}{x - x_V} &= \tan \alpha \\
                    y &= (\tan \alpha) (x - x_V) + y_V \\
                      &= (\tan \alpha) x - (\tan \alpha) x_V + y_V \\
                      &= \ell(x).
                    \end{align}
                </p>
                
                <p>
                    Now, given an $x \in \mathbb{R}$, 
                    \begin{aligned} 
                    t &= d((x, \ell(x)), (x_V, y_V)) \\
                      &= \sqrt{(x - x_V)^2 + (\ell(x) - y_V)^2},
                    \end{aligned}
                </p>
                
                <p>
                    which implies 
                    \[
                        \beta t^2 = \beta \big[ (x - x_V)^2 + (\ell(x) - y_V)^2 \big].
                    \]
                    Given $t \in \mathbb{R}$, we move from $V$ $t$ units towards positive part of 
                    $T$ and then $\beta t^2$ upwards. Note that, for example, if $\alpha \in (\pi / 2, 3\pi / 2)$,
                    "positive'' becomes "negative" and "upwards" becomes "downwards".  
                </p>
                
                <p>
                    Let $V_t$ be the point on a parabola with vertex $V$, vertex tangent angle $\alpha$ and the distance from $V$ $t$, the corresponding point $V_t$ is specified by 
                    \begin{aligned}
                        V_t &= V + (t\cos \alpha, t\sin \alpha) + (\beta t^2 \sin \alpha, \beta t^2 \cos \alpha) \\
                            &= (x_V + t\cos \alpha + \beta t^2 \sin \alpha, \; y_V + t \sin \alpha + \beta t^2 \cos \alpha)
                    \end{aligned}
                </p>    
                
                <p>
                The tangent line is obviously defined by $y = $
                In particular,
                Assuming the angle $\alpha$, its equation is

                <p>
                \begin{align}
                    \frac{y - y_V}{x - x_V} &= \tan \alpha \\
                    y - y_V &= (\tan \alpha)(x - x_V) \\
                    y &= (\tan \alpha)(x - x_V) + y_V \\
                    y &= (\tan \alpha)x + y_V - (\tan \alpha) x_V.
                \end{align}
                </p>
            </article>
        </div>
        
        <article>
            <p>Let $f(x) = x^n$, where $n \geq 0$.
\begin{aligned}
\frac{\mathrm{d}}{\mathrm{d}x}f(x)
    &= \lim_{h \to 0} \frac{f(x + h) - f(x)}{h} \\
    &= \lim_{h \to 0} \frac{(x + h)^n - x^n}{h}\\
    &= \lim_{h \to 0} \frac{\sum_{k = 0}^n \binom{n}{k} x^{n - k}h^k - x^n}{h} \\
    &= \lim_{h \to 0} \frac{x^n + nx^{n - 1}h + \sum_{k = 2}^n \binom{n}{k} x^{n - k}h^k - x^n}{h} \\
    &= \lim_{h \to 0} \big[ nx^{n - 1} \big] + \lim_{h \to 0}\Bigg[ \frac{h^2 \sum_{k=2}^n \binom{n}{k} x^{n - k}h^{k - 2} }{h} \Bigg] \\
    &= nx^{n - 1} + \lim_{h \to 0} \Bigg[ h \sum_{k = 2}^n \binom{n}{k}x^{n - k}h^{k - 2} \Bigg] \\
    &= nx^{n - 1}
    \end{aligned}</p>
<p>
Next, keeping $n$ in the set of non-negative integers, suppose $f(x) = x^{-n}$. Now we have
\begin{aligned}
\frac{\mathrm{d}}{\mathrm{d}x}f(x) &= \lim_{h \to 0} \frac{\frac{1}{(x + h)^n} - \frac{1}{x^n}} 
{h} \\
    &= \lim_{h \to 0} \frac{1}{h} \frac{x^n - (x + h)^n}{x^n (x + h)^n } \\
    &= \lim_{h \to 0} \frac{1}{h} \frac{x^n - \sum_{k = 0}^n \binom{n}{k} x^{n - k}h^k}{x^n (x + h)^n} \\
    &= \lim_{h \to 0} \frac{x^n - x^n - nx^{n - 1}h - \sum_{k = 2}^n \binom{n}{k} x^{n - k}h^k}{hx^n(x + h)^n} \\
    &= \lim_{h \to 0} \Bigg[ \frac{-nx^{n - 1}h}{hx^n (x + h)^n} - \frac{h^2\sum_{k = 2}^n \binom{n}{k} x^{n - k}h^{k - 2}}{hx^n (x + h)^n} \Bigg] \\
    &= \lim_{h \to 0} \frac{-nx^{n - 1}}{x^n (x + h)^n} - \lim_{h \to 0} h \frac{\sum_{k = 2}^n \binom{n}{k} x^{n - k}h^{k - 2}}{x^n(x + h)^n} \\
    &= \frac{\lim_{h \to 0} -nx^{n - 1}}{\lim_{h \to 0} x^n (x + h)^n} \\
    &= \frac{-nx^{n - 1}}{ x^{2n} } \\
    &= -nx^{-n - 1}.
\end{aligned}</p>
        </article>
    </body>
</html>
    